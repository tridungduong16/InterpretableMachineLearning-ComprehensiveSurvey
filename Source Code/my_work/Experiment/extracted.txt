
@article{lipton_mythos_2017,
	title = {The {Mythos} of {Model} {Interpretability}},
	urldate = {2020-03-08},
	journal = {arXiv:1606.03490 [cs, stat]},
	author = {Lipton, Zachary C.},
	month = mar,
	year = {2017},
	note = {arXiv: 1606.03490},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: presented at 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), New York, NY}
}

@article{hara_making_2017,
	title = {Making {Tree} {Ensembles} {Interpretable}: {A} {Bayesian} {Model} {Selection} {Approach}},
	shorttitle = {Making {Tree} {Ensembles} {Interpretable}},
	urldate = {2020-03-08},
	journal = {arXiv:1606.09066 [stat]},
	author = {Hara, Satoshi and Hayashi, Kohei},
	month = feb,
	year = {2017},
	note = {arXiv: 1606.09066},
	keywords = {Statistics - Machine Learning},
	annote = {Comment: 21 pages}
}

@incollection{guo_explaining_2018,
	title = {Explaining {Deep} {Learning} {Models} – {A} {Bayesian} {Non}-parametric {Approach}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Guo, Wenbo and Huang, Sui and Tao, Yunzhe and Xing, Xinyu and Lin, Lin},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {4514--4524}
}

@article{carvalho_machine_2019,
	title = {Machine {Learning} {Interpretability}: {A} {Survey} on {Methods} and {Metrics}},
	volume = {8},
	issn = {2079-9292},
	shorttitle = {Machine {Learning} {Interpretability}},
	doi = {10.3390/electronics8080832},
	language = {en},
	number = {8},
	urldate = {2020-03-07},
	journal = {Electronics},
	author = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
	month = jul,
	year = {2019},
	pages = {832}
}

@article{vedantam_probabilistic_2019,
	title = {Probabilistic {Neural}-symbolic {Models} for {Interpretable} {Visual} {Question} {Answering}},
	urldate = {2020-03-07},
	journal = {arXiv:1902.07864 [cs, stat]},
	author = {Vedantam, Ramakrishna and Desai, Karan and Lee, Stefan and Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
	month = jun,
	year = {2019},
	note = {arXiv: 1902.07864},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: ICML 2019 Camera Ready + Appendix}
}

@inproceedings{balog_transparent_2019,
	address = {Paris, France},
	title = {Transparent, {Scrutable} and {Explainable} {User} {Models} for {Personalized} {Recommendation}},
	isbn = {978-1-4503-6172-9},
	doi = {10.1145/3331184.3331211},
	language = {en},
	urldate = {2020-03-07},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}  - {SIGIR}'19},
	publisher = {ACM Press},
	author = {Balog, Krisztian and Radlinski, Filip and Arakelyan, Shushan},
	year = {2019},
	pages = {265--274}
}

@article{erion_learning_2019,
	title = {Learning {Explainable} {Models} {Using} {Attribution} {Priors}},
	abstract = {Two important topics in deep learning both involve incorporating humans into the modeling process: Model priors transfer information from humans to a model by constraining the model's parameters; Model attributions transfer information from a model to humans by explaining the model's behavior. We propose connecting these topics with attribution priors (https://github.com/suinleelab/attributionpriors), which allow humans to use the common language of attributions to enforce prior expectations about a model's behavior during training. We develop a differentiable axiomatic feature attribution method called expected gradients and show how to directly regularize these attributions during training. We demonstrate the broad applicability of attribution priors (\${\textbackslash}Omega\$) by presenting three distinct examples that regularize models to behave more intuitively in three different domains: 1) on image data, \${\textbackslash}Omega\_\{{\textbackslash}textrm\{pixel\}\}\$ encourages models to have piecewise smooth attribution maps; 2) on gene expression data, \${\textbackslash}Omega\_\{{\textbackslash}textrm\{graph\}\}\$ encourages models to treat functionally related genes similarly; 3) on a health care dataset, \${\textbackslash}Omega\_\{{\textbackslash}textrm\{sparse\}\}\$ encourages models to rely on fewer features. In all three domains, attribution priors produce models with more intuitive behavior and better generalization performance by encoding constraints that would otherwise be very difficult to encode using standard model priors.},
	urldate = {2020-03-07},
	journal = {arXiv:1906.10670 [cs, stat]},
	author = {Erion, Gabriel and Janizek, Joseph D. and Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.10670},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{afrabandpey_making_2019,
	title = {Making {Bayesian} {Predictive} {Models} {Interpretable}: {A} {Decision} {Theoretic} {Approach}},
	shorttitle = {Making {Bayesian} {Predictive} {Models} {Interpretable}},
	urldate = {2020-03-07},
	journal = {arXiv:1910.09358 [cs, stat]},
	author = {Afrabandpey, Homayun and Peltola, Tomi and Piironen, Juho and Vehtari, Aki and Kaski, Samuel},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.09358},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction}
}

@inproceedings{yan_groupinn_2019,
	address = {Anchorage, AK, USA},
	title = {{GroupINN}: {Grouping}-based {Interpretable} {Neural} {Network} for {Classification} of {Limited}, {Noisy} {Brain} {Data}},
	isbn = {978-1-4503-6201-6},
	shorttitle = {{GroupINN}},
	doi = {10.1145/3292500.3330921},
	language = {en},
	urldate = {2020-03-07},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Yan, Yujun and Zhu, Jiong and Duda, Marlena and Solarz, Eric and Sripada, Chandra and Koutra, Danai},
	year = {2019},
	pages = {772--782}
}

@inproceedings{yoshida_learning_2019,
	address = {Anchorage, AK, USA},
	title = {Learning {Interpretable} {Metric} between {Graphs}: {Convex} {Formulation} and {Computation} with {Graph} {Mining}},
	isbn = {978-1-4503-6201-6},
	shorttitle = {Learning {Interpretable} {Metric} between {Graphs}},
	doi = {10.1145/3292500.3330845},
	language = {en},
	urldate = {2020-03-07},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Yoshida, Tomoki and Takeuchi, Ichiro and Karasuyama, Masayuki},
	year = {2019},
	pages = {1026--1036}
}

@inproceedings{ming_interpretable_2019,
	address = {Anchorage, AK, USA},
	title = {Interpretable and {Steerable} {Sequence} {Learning} via {Prototypes}},
	isbn = {978-1-4503-6201-6},
	doi = {10.1145/3292500.3330908},
	language = {en},
	urldate = {2020-03-07},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Ming, Yao and Xu, Panpan and Qu, Huamin and Ren, Liu},
	year = {2019},
	pages = {903--913}
}

@inproceedings{jia_improving_2019,
	address = {Anchorage, AK, USA},
	title = {Improving the {Quality} of {Explanations} with {Local} {Embedding} {Perturbations}},
	isbn = {978-1-4503-6201-6},
	doi = {10.1145/3292500.3330930},
	language = {en},
	urldate = {2020-03-06},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Jia, Yunzhe and Bailey, James and Ramamohanarao, Kotagiri and Leckie, Christopher and Houle, Michael E.},
	year = {2019},
	pages = {875--884}
}

@article{guo_survey_2019,
	title = {A {Survey} of {Learning} {Causality} with {Data}: {Problems} and {Methods}},
	shorttitle = {A {Survey} of {Learning} {Causality} with {Data}},
	urldate = {2020-03-06},
	journal = {arXiv:1809.09337 [cs, stat]},
	author = {Guo, Ruocheng and Cheng, Lu and Li, Jundong and Hahn, P. Richard and Liu, Huan},
	month = apr,
	year = {2019},
	note = {arXiv: 1809.09337},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Comment: 35 pages, under review}
}

@article{yao_survey_2020,
	title = {A {Survey} on {Causal} {Inference}},
	urldate = {2020-03-06},
	journal = {arXiv:2002.02770 [cs, stat]},
	author = {Yao, Liuyi and Chu, Zhixuan and Li, Sheng and Li, Yaliang and Gao, Jing and Zhang, Aidong},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.02770},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Methodology}
}

@article{mohseni_multidisciplinary_2019,
	title = {A {Multidisciplinary} {Survey} and {Framework} for {Design} and {Evaluation} of {Explainable} {AI} {Systems}},
	urldate = {2020-03-06},
	journal = {arXiv:1811.11839 [cs]},
	author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D.},
	month = dec,
	year = {2019},
	note = {arXiv: 1811.11839},
	keywords = {Computer Science - Human-Computer Interaction}
}

@article{arik_tabnet_2019,
	title = {{TabNet}: {Attentive} {Interpretable} {Tabular} {Learning}},
	journal = {arXiv preprint arXiv:1908.07442},
	author = {Arik, Sercan O and Pfister, Tomas},
	year = {2019}
}

@article{zhang_explainable_2018,
	title = {Explainable recommendation: {A} survey and new perspectives},
	journal = {arXiv preprint arXiv:1804.11192},
	author = {Zhang, Yongfeng and Chen, Xu},
	year = {2018}
}

@inproceedings{ribeiro__2016,
	title = {" {Why} should i trust you?" {Explaining} the predictions of any classifier},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} international conference on knowledge discovery and data mining},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	pages = {1135--1144}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{guidotti2018local,
  title={Local rule-based explanations of black box decision systems},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Pedreschi, Dino and Turini, Franco and Giannotti, Fosca},
  journal={arXiv preprint arXiv:1805.10820},
  year={2018}
}



@inproceedings{zang_learning_2018,
	address = {London United Kingdom},
	title = {Learning and {Interpreting} {Complex} {Distributions} in {Empirical} {Data}},
	isbn = {978-1-4503-5552-0},
	doi = {10.1145/3219819.3220073},
	language = {en},
	urldate = {2020-03-09},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Zang, Chengxi and Cui, Peng and Zhu, Wenwu},
	month = jul,
	year = {2018},
	pages = {2682--2691}
}

@inproceedings{liu_interpretation_2018,
	address = {London United Kingdom},
	title = {On {Interpretation} of {Network} {Embedding} via {Taxonomy} {Induction}},
	isbn = {978-1-4503-5552-0},
	doi = {10.1145/3219819.3220001},
	language = {en},
	urldate = {2020-03-09},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Liu, Ninghao and Huang, Xiao and Li, Jundong and Hu, Xia},
	month = jul,
	year = {2018},
	pages = {1812--1820}
}

@inproceedings{peake_explanation_2018,
	address = {London United Kingdom},
	title = {Explanation {Mining}: {Post} {Hoc} {Interpretability} of {Latent} {Factor} {Models} for {Recommendation} {Systems}},
	isbn = {978-1-4503-5552-0},
	shorttitle = {Explanation {Mining}},
	doi = {10.1145/3219819.3220072},
	language = {en},
	urldate = {2020-03-09},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Peake, Georgina and Wang, Jun},
	month = jul,
	year = {2018},
	pages = {2060--2069}
}

@inproceedings{tolomei_interpretable_2017,
	address = {Halifax, NS, Canada},
	title = {Interpretable {Predictions} of {Tree}-based {Ensembles} via {Actionable} {Feature} {Tweaking}},
	isbn = {978-1-4503-4887-4},
	doi = {10.1145/3097983.3098039},
	language = {en},
	urldate = {2020-03-09},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}  - {KDD} '17},
	publisher = {ACM Press},
	author = {Tolomei, Gabriele and Silvestri, Fabrizio and Haines, Andrew and Lalmas, Mounia},
	year = {2017},
	pages = {465--474}
}

@article{ai_learning_2018,
	title = {Learning {Heterogeneous} {Knowledge} {Base} {Embeddings} for {Explainable} {Recommendation}},
	volume = {11},
	issn = {1999-4893},
	doi = {10.3390/a11090137},
	language = {en},
	number = {9},
	urldate = {2020-03-09},
	journal = {Algorithms},
	author = {Ai, Qingyao and Azizi, Vahid and Chen, Xu and Zhang, Yongfeng},
	month = sep,
	year = {2018},
	pages = {137}
}

@article{miller_explanation_2019,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {00043702},
	shorttitle = {Explanation in artificial intelligence},
	doi = {10.1016/j.artint.2018.07.007},
	language = {en},
	urldate = {2020-03-10},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	month = feb,
	year = {2019},
	pages = {1--38}
}

@article{miller_but_2019,
	title = {"{But} why?": understanding explainable artificial intelligence},
	volume = {25},
	issn = {15284972},
	shorttitle = {"{But} why?},
	doi = {10.1145/3313107},
	language = {en},
	number = {3},
	urldate = {2020-03-10},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {Miller, Tim},
	month = apr,
	year = {2019},
	pages = {20--25}
}

@inproceedings{alvarez-melis_causal_2017,
	address = {Copenhagen, Denmark},
	title = {A causal framework for explaining the predictions of black-box sequence-to-sequence models},
	doi = {10.18653/v1/D17-1042},
	language = {en},
	urldate = {2020-03-10},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Alvarez-Melis, David and Jaakkola, Tommi},
	year = {2017},
	pages = {412--421}
}

@article{ghorbani_towards_2019,
	title = {Towards {Automatic} {Concept}-based {Explanations}},
	abstract = {Interpretability has become an important topic of research as more machine learning (ML) models are deployed and widely used to make important decisions. Most of the current explanation methods provide explanations through feature importance scores, which identify features that are important for each individual input. However, how to systematically summarize and interpret such per sample feature importance scores itself is challenging. In this work, we propose principles and desiderata for {\textbackslash}emph\{concept\} based explanation, which goes beyond per-sample features to identify higher-level human-understandable concepts that apply across the entire dataset. We develop a new algorithm, ACE, to automatically extract visual concepts. Our systematic experiments demonstrate that {\textbackslash}alg discovers concepts that are human-meaningful, coherent and important for the neural network's predictions.},
	urldate = {2020-03-10},
	journal = {arXiv:1902.03129 [cs, stat]},
	author = {Ghorbani, Amirata and Wexler, James and Zou, James and Kim, Been},
	month = oct,
	year = {2019},
	note = {arXiv: 1902.03129},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition}
}

@article{saumitra_mishra_local_2017,
	title = {Local {Interpretable} {Model}-{Agnostic} {Explanations} {For} {Music} {Content} {Analysis}.},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	doi = {10.5281/ZENODO.1417387},
	urldate = {2020-03-27},
	author = {Saumitra Mishra and Sturm, Bob L. and Dixon, Simon},
	month = oct,
	year = {2017},
	note = {Publisher: Zenodo}
}

@article{lucic_explaining_2019,
	title = {Explaining {Predictions} from {Tree}-based {Boosting} {Ensembles}},
	urldate = {2020-03-16},
	journal = {arXiv:1907.02582 [cs, stat]},
	author = {Lucic, Ana and Haned, Hinda and de Rijke, Maarten},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.02582},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
	annote = {Comment: SIGIR 2019: FACTS-IR Workshop}
}


@article{jiang_trust_2018,
	title = {To {Trust} {Or} {Not} {To} {Trust} {A} {Classifier}},
	urldate = {2020-03-10},
	journal = {arXiv:1805.11783 [cs, stat]},
	author = {Jiang, Heinrich and Kim, Been and Guan, Melody Y. and Gupta, Maya},
	month = oct,
	year = {2018},
	note = {arXiv: 1805.11783},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: NIPS 2018}
}

@article{holzinger_causability_2019,
	title = {Causability and explainability of artificial intelligence in medicine},
	volume = {9},
	issn = {1942-4787, 1942-4795},
	doi = {10.1002/widm.1312},
	language = {en},
	number = {4},
	urldate = {2020-03-10},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Holzinger, Andreas and Langs, Georg and Denk, Helmut and Zatloukal, Kurt and Müller, Heimo},
	month = jul,
	year = {2019}
}

@article{kim_bayesian_2015,
	title = {The {Bayesian} {Case} {Model}: {A} {Generative} {Approach} for {Case}-{Based} {Reasoning} and {Prototype} {Classification}},
	shorttitle = {The {Bayesian} {Case} {Model}},
	urldate = {2020-03-10},
	journal = {arXiv:1503.01161 [cs, stat]},
	author = {Kim, Been and Rudin, Cynthia and Shah, Julie},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.01161},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published in Neural Information Processing Systems (NIPS) 2014, Neural Information Processing Systems (NIPS) 2014}
}

@inproceedings{zhang_axiomatic_2019,
	address = {Anchorage, AK, USA},
	title = {Axiomatic {Interpretability} for {Multiclass} {Additive} {Models}},
	isbn = {978-1-4503-6201-6},
	doi = {10.1145/3292500.3330898},
	language = {en},
	urldate = {2020-03-11},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Zhang, Xuezhou and Tan, Sarah and Koch, Paul and Lou, Yin and Chajewska, Urszula and Caruana, Rich},
	year = {2019},
	pages = {226--234}
}

@article{wachter_counterfactual_2018,
	title = {Counterfactual {Explanations} without {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	shorttitle = {Counterfactual {Explanations} without {Opening} the {Black} {Box}},
	urldate = {2020-03-11},
	journal = {arXiv:1711.00399 [cs]},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	month = mar,
	year = {2018},
	note = {arXiv: 1711.00399},
	keywords = {Computer Science - Artificial Intelligence}
}

@article{van_looveren_interpretable_2020,
	title = {Interpretable {Counterfactual} {Explanations} {Guided} by {Prototypes}},
	abstract = {We propose a fast, model agnostic method for finding interpretable counterfactual explanations of classifier predictions by using class prototypes. We show that class prototypes, obtained using either an encoder or through class specific k-d trees, significantly speed up the the search for counterfactual instances and result in more interpretable explanations. We introduce two novel metrics to quantitatively evaluate local interpretability at the instance level. We use these metrics to illustrate the effectiveness of our method on an image and tabular dataset, respectively MNIST and Breast Cancer Wisconsin (Diagnostic). The method also eliminates the computational bottleneck that arises because of numerical gradient evaluation for \${\textbackslash}textit\{black box\}\$ models.},
	urldate = {2020-03-11},
	journal = {arXiv:1907.02584 [cs, stat]},
	author = {Van Looveren, Arnaud and Klaise, Janis},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.02584},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 17 pages, 13 figures. For an open source implementation of the algorithm, see https://github.com/SeldonIO/alibi}
}

@inproceedings{mothilal_explaining_2020,
	address = {Barcelona Spain},
	title = {Explaining machine learning classifiers through diverse counterfactual explanations},
	isbn = {978-1-4503-6936-7},
	doi = {10.1145/3351095.3372850},
	language = {en},
	urldate = {2020-03-11},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
	month = jan,
	year = {2020},
	pages = {607--617}
}

@article{hayes_causal_2018,
	title = {Causal explanation improves judgment under uncertainty, but rarely in a {Bayesian} way},
	volume = {46},
	issn = {0090-502X, 1532-5946},
	doi = {10.3758/s13421-017-0750-z},
	language = {en},
	number = {1},
	urldate = {2020-03-11},
	journal = {Memory \& Cognition},
	author = {Hayes, Brett K. and Ngo, Jeremy and Hawkins, Guy E. and Newell, Ben R.},
	month = jan,
	year = {2018},
	pages = {112--131}
}

@article{schwab_cxplain_2019,
	title = {{CXPlain}: {Causal} {Explanations} for {Model} {Interpretation} under {Uncertainty}},
	shorttitle = {{CXPlain}},
	urldate = {2020-03-11},
	journal = {arXiv:1910.12336 [cs, stat]},
	author = {Schwab, Patrick and Karlen, Walter},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.12336},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: To appear in Advances in Neural Information Processing Systems 2019}
}

@article{wang_multi-value_2017,
	title = {Multi-{Value} {Rule} {Sets}},
	urldate = {2020-03-11},
	journal = {arXiv:1710.05257 [cs], NIPS},
	author = {Wang, Tong},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.05257},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Data Structures and Algorithms}
}

@article{kim_learning_2019,
	title = {Learning {Interpretable} {Models} with {Causal} {Guarantees}},
	urldate = {2020-03-12},
	journal = {arXiv:1901.08576 [cs, stat]},
	author = {Kim, Carolyn and Bastani, Osbert},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.08576},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{goyal_counterfactual_2019,
	title = {Counterfactual {Visual} {Explanations}},
	urldate = {2020-03-12},
	journal = {arXiv:1904.07451 [cs, stat], ICML},
	author = {Goyal, Yash and Wu, Ziyan and Ernst, Jan and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	month = jun,
	year = {2019},
	note = {arXiv: 1904.07451},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition}
}

@article{ancona_explaining_2019,
	title = {Explaining {Deep} {Neural} {Networks} with a {Polynomial} {Time} {Algorithm} for {Shapley} {Values} {Approximation}},
	urldate = {2020-03-12},
	journal = {arXiv:1903.10992 [cs, stat]},
	author = {Ancona, Marco and Öztireli, Cengiz and Gross, Markus},
	month = jun,
	year = {2019},
	note = {arXiv: 1903.10992},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICML 2019}
}

@article{chen_learning_2018,
	title = {Learning to {Explain}: {An} {Information}-{Theoretic} {Perspective} on {Model} {Interpretation}},
	shorttitle = {Learning to {Explain}},
	urldate = {2020-03-12},
	journal = {arXiv:1802.07814 [cs, stat], ICML 2018},
	author = {Chen, Jianbo and Song, Le and Wainwright, Martin J. and Jordan, Michael I.},
	month = jun,
	year = {2018},
	note = {arXiv: 1802.07814},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Accepted to ICML 2018 as a long oral}
}

@inproceedings{hara_making_2018,
	address = {Playa Blanca, Lanzarote, Canary Islands},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Making {Tree} {Ensembles} {Interpretable}: {A} {Bayesian} {Model} {Selection} {Approach}},
	volume = {84},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Hara, Satoshi and Hayashi, Kohei},
	editor = {Storkey, Amos and Perez-Cruz, Fernando},
	month = apr,
	year = {2018},
	pages = {77--85}
}

@article{fox_explainable_2017,
	title = {Explainable {Planning}},
	urldate = {2020-03-13},
	journal = {arXiv:1709.10256 [cs]},
	author = {Fox, Maria and Long, Derek and Magazzeni, Daniele},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.10256},
	keywords = {Computer Science - Artificial Intelligence, I.2, I.2.9},
	annote = {Comment: Presented at the IJCAI-17 workshop on Explainable AI (http://home.earthlink.net/{\textasciitilde}dwaha/research/meetings/ijcai17-xai/). Melbourne, August 2017}
}

@article{gilpin_explaining_2019,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	urldate = {2020-03-13},
	journal = {arXiv:1806.00069 [cs, stat]},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = feb,
	year = {2019},
	note = {arXiv: 1806.00069},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: The 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA 2018). [Research Track]}
}

@article{kailkhura_reliable_2019,
	title = {Reliable and explainable machine-learning methods for accelerated material discovery},
	volume = {5},
	issn = {2057-3960},
	doi = {10.1038/s41524-019-0248-2},
	language = {en},
	number = {1},
	urldate = {2020-03-13},
	journal = {npj Computational Materials},
	author = {Kailkhura, Bhavya and Gallagher, Brian and Kim, Sookyung and Hiszpanski, Anna and Han, T. Yong-Jin},
	month = dec,
	year = {2019},
	pages = {108}
}

@article{timonen_interpretable_2019,
	title = {An interpretable probabilistic machine learning method for heterogeneous longitudinal studies},
	urldate = {2020-03-13},
	journal = {arXiv:1912.03549 [cs, q-bio, stat]},
	author = {Timonen, Juho and Mannerström, Henrik and Vehtari, Aki and Lähdesmäki, Harri},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.03549},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology, Quantitative Biology - Quantitative Methods},
	annote = {Comment: 25 pages, 10 Figures. Tables S1-S2 in an ancillary file}
}

@inproceedings{li_learning_2019,
	address = {Macao, China},
	title = {Learning {Interpretable} {Deep} {State} {Space} {Model} for {Probabilistic} {Time} {Series} {Forecasting}},
	isbn = {978-0-9992411-4-1},
	doi = {10.24963/ijcai.2019/402},
	language = {en},
	urldate = {2020-03-13},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Li, Longyuan and Yan, Junchi and Yang, Xiaokang and Jin, Yaohui},
	month = aug,
	year = {2019},
	pages = {2901--2908}
}

@incollection{filchenkov_interpretable_2018,
	address = {Cham},
	title = {Interpretable {Probabilistic} {Embeddings}: {Bridging} the {Gap} {Between} {Topic} {Models} and {Neural} {Networks}},
	volume = {789},
	isbn = {978-3-319-71745-6 978-3-319-71746-3},
	shorttitle = {Interpretable {Probabilistic} {Embeddings}},
	urldate = {2020-03-13},
	booktitle = {Artificial {Intelligence} and {Natural} {Language}},
	publisher = {Springer International Publishing},
	author = {Potapenko, Anna and Popov, Artem and Vorontsov, Konstantin},
	editor = {Filchenkov, Andrey and Pivovarova, Lidia and Žižka, Jan},
	year = {2018},
	doi = {10.1007/978-3-319-71746-3_15},
	note = {Series Title: Communications in Computer and Information Science},
	pages = {167--180}
}

@article{odom_human-guided_2018,
	title = {Human-{Guided} {Learning} for {Probabilistic} {Logic} {Models}},
	volume = {5},
	issn = {2296-9144},
	doi = {10.3389/frobt.2018.00056},
	urldate = {2020-03-13},
	journal = {Frontiers in Robotics and AI},
	author = {Odom, Phillip and Natarajan, Sriraam},
	month = jun,
	year = {2018},
	pages = {56}
}

@article{levray_learning_2019,
	title = {Learning {Tractable} {Probabilistic} {Models} in {Open} {Worlds}},
	urldate = {2020-03-13},
	journal = {arXiv:1901.05847 [cs, stat]},
	author = {Levray, Amelie and Belle, Vaishak},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.05847},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science}
}

@article{letham_interpretable_2015,
	title = {Interpretable classifiers using rules and {Bayesian} analysis: {Building} a better stroke prediction model},
	volume = {9},
	issn = {1932-6157},
	shorttitle = {Interpretable classifiers using rules and {Bayesian} analysis},
	doi = {10.1214/15-AOAS848},
	number = {3},
	urldate = {2020-03-13},
	journal = {The Annals of Applied Statistics},
	author = {Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H. and Madigan, David},
	month = sep,
	year = {2015},
	note = {arXiv: 1511.01644},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Applications},
	pages = {1350--1371},
	annote = {Comment: Published at http://dx.doi.org/10.1214/15-AOAS848 in the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org)}
}

@article{arrieta_explainable_2019,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	urldate = {2020-03-13},
	journal = {arXiv:1910.10045 [cs]},
	author = {Arrieta, Alejandro Barredo and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = dec,
	year = {2019},
	note = {arXiv: 1910.10045},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 67 pages, 13 figures, accepted for its publication in Information Fusion}
}

@article{harder_interpretable_2019,
	title = {Interpretable and {Differentially} {Private} {Predictions}},
	urldate = {2020-03-14},
	journal = {arXiv:1906.02004 [cs, stat]},
	author = {Harder, Frederik and Bauer, Matthias and Park, Mijung},
	month = oct,
	year = {2019},
	note = {arXiv: 1906.02004},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{dong_asymmetrical_2019,
	title = {Asymmetrical {Hierarchical} {Networks} with {Attentive} {Interactions} for {Interpretable} {Review}-{Based} {Recommendation}},
	urldate = {2020-03-14},
	journal = {arXiv:2001.04346 [cs], AAAI20},
	author = {Dong, Xin and Ni, Jingchao and Cheng, Wei and Chen, Zhengzhang and Zong, Bo and Song, Dongjin and Liu, Yanchi and Chen, Haifeng and de Melo, Gerard},
	month = dec,
	year = {2019},
	note = {arXiv: 2001.04346},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval}
}

@article{lundberg_explainable_2019,
	title = {Explainable {AI} for {Trees}: {From} {Local} {Explanations} to {Global} {Understanding}},
	shorttitle = {Explainable {AI} for {Trees}},
	urldate = {2020-03-15},
	journal = {arXiv:1905.04610 [cs, stat]},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = may,
	year = {2019},
	note = {arXiv: 1905.04610},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence}
}

@article{du_techniques_2019,
	title = {Techniques for {Interpretable} {Machine} {Learning}},
	urldate = {2020-03-15},
	journal = {arXiv:1808.00033 [cs, stat]},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	month = may,
	year = {2019},
	note = {arXiv: 1808.00033},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, read, good},
	annote = {Comment: Accepted by Communications of the ACM (CACM), Review Article}
}

@article{klein_explaining_2018,
	title = {Explaining {Explanation}, {Part} 3: {The} {Causal} {Landscape}},
	volume = {33},
	issn = {1541-1672},
	shorttitle = {Explaining {Explanation}, {Part} 3},
	doi = {10.1109/MIS.2018.022441353},
	number = {2},
	urldate = {2020-03-15},
	journal = {IEEE Intelligent Systems},
	author = {Klein, Gary},
	month = mar,
	year = {2018},
	pages = {83--88}
}

@article{lucic_explaining_2019,
	title = {Explaining {Predictions} from {Tree}-based {Boosting} {Ensembles}},
	urldate = {2020-03-16},
	journal = {arXiv:1907.02582 [cs, stat]},
	author = {Lucic, Ana and Haned, Hinda and de Rijke, Maarten},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.02582},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
	annote = {Comment: SIGIR 2019: FACTS-IR Workshop}
}

@article{bastani_interpretability_2018,
	title = {Interpretability via {Model} {Extraction}},
	urldate = {2020-03-16},
	journal = {arXiv:1706.09773 [cs, stat]},
	author = {Bastani, Osbert and Kim, Carolyn and Bastani, Hamsa},
	month = mar,
	year = {2018},
	note = {arXiv: 1706.09773},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society},
	annote = {Comment: Presented as a poster at the 2017 Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT/ML 2017)}
}

@article{ross_right_2017,
	title = {Right for the {Right} {Reasons}: {Training} {Differentiable} {Models} by {Constraining} their {Explanations}},
	shorttitle = {Right for the {Right} {Reasons}},
	urldate = {2020-03-17},
	journal = {arXiv:1703.03717 [cs, stat]},
	author = {Ross, Andrew Slavin and Hughes, Michael C. and Doshi-Velez, Finale},
	month = may,
	year = {2017},
	note = {arXiv: 1703.03717},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence}
}

@article{moraffah_causal_2020,
	title = {Causal {Interpretability} for {Machine} {Learning} -- {Problems}, {Methods} and {Evaluation}},
	abstract = {Machine learning models have had discernible achievements in a myriad of applications. However, most of these models are black-boxes, and it is obscure how the decisions are made by them. This makes the models unreliable and untrustworthy. To provide insights into the decision making processes of these models, a variety of traditional interpretable models have been proposed. Moreover, to generate more human-friendly explanations, recent work on interpretability tries to answer questions related to causality such as {\textbackslash}Why does this model makes such decisions?" or {\textbackslash}Was it a specific feature that caused the decision made by the model?". In this work, models that aim to answer causal questions are referred to as causal interpretable models. The existing surveys have covered concepts and methodologies of traditional interpretability. In this work, we present a comprehensive survey on causal interpretable models from the aspects of the problems and methods. In addition, this survey provides in-depth insights into the existing evaluation metrics for measuring interpretability, which can help practitioners understand for what scenarios each evaluation metric is suitable.},
	urldate = {2020-03-17},
	journal = {arXiv:2003.03934 [cs, stat]},
	author = {Moraffah, Raha and Karami, Mansooreh and Guo, Ruocheng and Raglin, Adrienne and Liu, Huan},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.03934},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{pan_interpretable_2020,
	title = {Interpretable {Companions} for {Black}-{Box} {Models}},
	urldate = {2020-03-18},
	journal = {arXiv:2002.03494 [cs, stat]},
	author = {Pan, Danqing and Wang, Tong and Hara, Satoshi},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.03494},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 15 pages, 6 figures}
}

@article{grath_interpretable_2018,
	title = {Interpretable {Credit} {Application} {Predictions} {With} {Counterfactual} {Explanations}},
	urldate = {2020-03-22},
	journal = {arXiv:1811.05245 [cs]},
	author = {Grath, Rory Mc and Costabello, Luca and Van, Chan Le and Sweeney, Paul and Kamiab, Farbod and Shen, Zhao and Lecue, Freddy},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.05245},
	keywords = {Computer Science - Artificial Intelligence}
}

@inproceedings{chakraborty_interpretability_2017,
	address = {San Francisco, CA},
	title = {Interpretability of deep learning models: {A} survey of results},
	isbn = {978-1-5386-0435-9},
	shorttitle = {Interpretability of deep learning models},
	doi = {10.1109/UIC-ATC.2017.8397411},
	urldate = {2020-03-22},
	booktitle = {2017 {IEEE} {SmartWorld}, {Ubiquitous} {Intelligence} \& {Computing}, {Advanced} \& {Trusted} {Computed}, {Scalable} {Computing} \& {Communications}, {Cloud} \& {Big} {Data} {Computing}, {Internet} of {People} and {Smart} {City} {Innovation} ({SmartWorld}/{SCALCOM}/{UIC}/{ATC}/{CBDCom}/{IOP}/{SCI})},
	publisher = {IEEE},
	author = {Chakraborty, Supriyo and Tomsett, Richard and Raghavendra, Ramya and Harborne, Daniel and Alzantot, Moustafa and Cerutti, Federico and Srivastava, Mani and Preece, Alun and Julier, Simon and Rao, Raghuveer M. and Kelley, Troy D. and Braines, Dave and Sensoy, Murat and Willis, Christopher J. and Gurram, Prudhvi},
	month = aug,
	year = {2017},
	pages = {1--6}
}

@inproceedings{caruana_intelligible_2015,
	address = {Sydney, NSW, Australia},
	title = {Intelligible {Models} for {HealthCare}: {Predicting} {Pneumonia} {Risk} and {Hospital} 30-day {Readmission}},
	isbn = {978-1-4503-3664-2},
	shorttitle = {Intelligible {Models} for {HealthCare}},
	doi = {10.1145/2783258.2788613},
	language = {en},
	urldate = {2020-03-23},
	booktitle = {Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '15},
	publisher = {ACM Press},
	author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
	year = {2015},
	pages = {1721--1730}
}

@inproceedings{russell_efficient_2019,
	address = {Atlanta, GA, USA},
	title = {Efficient {Search} for {Diverse} {Coherent} {Explanations}},
	isbn = {978-1-4503-6125-5},
	doi = {10.1145/3287560.3287569},
	language = {en},
	urldate = {2020-03-23},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency} - {FAT}* '19},
	publisher = {ACM Press},
	author = {Russell, Chris},
	year = {2019},
	pages = {20--28}
}

@inproceedings{garg_counterfactual_2019,
	address = {Honolulu HI USA},
	title = {Counterfactual {Fairness} in {Text} {Classification} through {Robustness}},
	isbn = {978-1-4503-6324-2},
	doi = {10.1145/3306618.3317950},
	language = {en},
	urldate = {2020-03-23},
	booktitle = {Proceedings of the 2019 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Garg, Sahaj and Perot, Vincent and Limtiaco, Nicole and Taly, Ankur and Chi, Ed H. and Beutel, Alex},
	month = jan,
	year = {2019},
	pages = {219--226}
}

@incollection{ghorbani_towards_2019-1,
	title = {Towards {Automatic} {Concept}-based {Explanations}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {9277--9286}
}

@incollection{kim_learning_2019-1,
	title = {Learning {Dynamics} of {Attention}: {Human} {Prior} for {Interpretable} {Machine} {Reasoning}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Kim, Wonjae and Lee, Yoonho},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {6021--6032}
}

@article{goyal_explaining_2020,
	title = {Explaining {Classifiers} with {Causal} {Concept} {Effect} ({CaCE})},
	urldate = {2020-03-24},
	journal = {arXiv:1907.07165 [cs, stat]},
	author = {Goyal, Yash and Feder, Amir and Shalit, Uri and Kim, Been},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.07165},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{liu_generative_2019,
	title = {Generative {Counterfactual} {Introspection} for {Explainable} {Deep} {Learning}},
	urldate = {2020-03-24},
	journal = {arXiv:1907.03077 [cs, stat]},
	author = {Liu, Shusen and Kailkhura, Bhavya and Loveland, Donald and Han, Yong},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.03077},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{bertsimas_price_2019,
	title = {The {Price} of {Interpretability}},
	urldate = {2020-03-24},
	journal = {arXiv:1907.03419 [cs, stat]},
	author = {Bertsimas, Dimitris and Delarue, Arthur and Jaillet, Patrick and Martin, Sebastien},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.03419},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{miller_explanation_2019-1,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {00043702},
	shorttitle = {Explanation in artificial intelligence},
	doi = {10.1016/j.artint.2018.07.007},
	language = {en},
	urldate = {2020-03-24},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	month = feb,
	year = {2019},
	pages = {1--38}
}

@article{du_techniques_2019-1,
	title = {Techniques for {Interpretable} {Machine} {Learning}},
	urldate = {2020-03-24},
	journal = {arXiv:1808.00033 [cs, stat]},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	month = may,
	year = {2019},
	note = {arXiv: 1808.00033},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted by Communications of the ACM (CACM), Review Article}
}

@article{arrieta_explainable_2019-1,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	urldate = {2020-03-24},
	journal = {arXiv:1910.10045 [cs]},
	author = {Arrieta, Alejandro Barredo and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = dec,
	year = {2019},
	note = {arXiv: 1910.10045},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 67 pages, 13 figures, accepted for its publication in Information Fusion}
}

@article{lage_evaluation_2019,
	title = {An {Evaluation} of the {Human}-{Interpretability} of {Explanation}},
	urldate = {2020-03-24},
	journal = {arXiv:1902.00006 [cs, stat]},
	author = {Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
	month = aug,
	year = {2019},
	note = {arXiv: 1902.00006},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: arXiv admin note: substantial text overlap with arXiv:1802.00682}
}

@inproceedings{ghazimatin_prince_2020,
	address = {Houston TX USA},
	title = {{PRINCE}: {Provider}-side {Interpretability} with {Counterfactual} {Explanations} in {Recommender} {Systems}},
	isbn = {978-1-4503-6822-3},
	shorttitle = {{PRINCE}},
	doi = {10.1145/3336191.3371824},
	language = {en},
	urldate = {2020-03-24},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ghazimatin, Azin and Balalau, Oana and Saha Roy, Rishiraj and Weikum, Gerhard},
	month = jan,
	year = {2020},
	pages = {196--204}
}

@inproceedings{gilpin_explaining_2018,
	address = {Turin, Italy},
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	isbn = {978-1-5386-5090-5},
	shorttitle = {Explaining {Explanations}},
	doi = {10.1109/DSAA.2018.00018},
	urldate = {2020-03-24},
	booktitle = {2018 {IEEE} 5th {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
	publisher = {IEEE},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = oct,
	year = {2018},
	pages = {80--89}
}

@article{lakkaraju_interpretable_2017,
	title = {Interpretable \& {Explorable} {Approximations} of {Black} {Box} {Models}},
	urldate = {2020-03-24},
	journal = {arXiv:1707.01154 [cs]},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.01154},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: Presented as a poster at the 2017 Workshop on Fairness, Accountability, and Transparency in Machine Learning}
}

@article{guidotti_survey_2018,
	title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
	volume = {51},
	issn = {03600300},
	doi = {10.1145/3236009},
	language = {en},
	number = {5},
	urldate = {2020-03-24},
	journal = {ACM Computing Surveys},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	month = aug,
	year = {2018},
	pages = {1--42}
}

@inproceedings{ghazimatin_prince_2020-1,
	address = {Houston TX USA},
	title = {{PRINCE}: {Provider}-side {Interpretability} with {Counterfactual} {Explanations} in {Recommender} {Systems}},
	isbn = {978-1-4503-6822-3},
	shorttitle = {{PRINCE}},
	doi = {10.1145/3336191.3371824},
	language = {en},
	urldate = {2020-03-24},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ghazimatin, Azin and Balalau, Oana and Saha Roy, Rishiraj and Weikum, Gerhard},
	month = jan,
	year = {2020},
	pages = {196--204}
}

@article{rudin_stop_2019,
	title = {Stop {Explaining} {Black} {Box} {Machine} {Learning} {Models} for {High} {Stakes} {Decisions} and {Use} {Interpretable} {Models} {Instead}},
	abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to {\textbackslash}textit\{explain\} black box models, rather than creating models that are {\textbackslash}textit\{interpretable\} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
	urldate = {2020-03-25},
	journal = {arXiv:1811.10154 [cs, stat]},
	author = {Rudin, Cynthia},
	month = sep,
	year = {2019},
	note = {arXiv: 1811.10154},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Author's pre-publication version of a 2019 Nature Machine Intelligence article. Shorter Version was published in NIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning. Expands also on NSF Statistics at a Crossroads Webinar}
}

@article{hendricks2018generating,
  title={Generating counterfactual explanations with natural language},
  author={Hendricks, Lisa Anne and Hu, Ronghang and Darrell, Trevor and Akata, Zeynep},
  journal={arXiv preprint arXiv:1806.09809},
  year={2018}
}

@article{artelt2020convex,
  title={Convex Density Constraints for Computing Plausible Counterfactual Explanations},
  author={Artelt, Andr{\'e} and Hammer, Barbara},
  journal={arXiv preprint arXiv:2002.04862},
  year={2020}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in neural information processing systems},
  pages={4765--4774},
  year={2017}
}

@inproceedings{dhurandhar2018explanations,
  title={Explanations based on the missing: Towards contrastive explanations with pertinent negatives},
  author={Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  booktitle={Advances in neural information processing systems},
  pages={592--603},
  year={2018}
}

@article{sharma2019certifai,
  title={Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models},
  author={Sharma, Shubham and Henderson, Jette and Ghosh, Joydeep},
  journal={arXiv preprint arXiv:1905.07857},
  year={2019}
}


@article{chattopadhyay2019neural,
  title={Neural network attributions: A causal perspective},
  author={Chattopadhyay, Aditya and Manupriya, Piyushi and Sarkar, Anirban and Balasubramanian, Vineeth N},
  journal={arXiv preprint arXiv:1902.02302},
  year={2019}
}

@article{parafita2019explaining,
  title={Explaining Visual Models by Causal Attribution},
  author={Parafita, {\'A}lvaro and Vitri{\`a}, Jordi},
  journal={arXiv preprint arXiv:1909.08891},
  year={2019}
}


@article{narendra2018explaining,
  title={Explaining deep learning models using causal inference},
  author={Narendra, Tanmayee and Sankaran, Anush and Vijaykeerthy, Deepak and Mani, Senthil},
  journal={arXiv preprint arXiv:1811.04376},
  year={2018}
}



@article{alvarez2017causal,
  title={A causal framework for explaining the predictions of black-box sequence-to-sequence models},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1707.01943},
  year={2017}
}

@inproceedings{zhang2019axiomatic,
  title={Axiomatic Interpretability for Multiclass Additive Models},
  author={Zhang, Xuezhou and Tan, Sarah and Koch, Paul and Lou, Yin and Chajewska, Urszula and Caruana, Rich},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={226--234},
  year={2019}
}

@article{darwen2019bayesian,
  title={Bayesian model averaging for river flow prediction},
  author={Darwen, Paul J},
  journal={Applied Intelligence},
  volume={49},
  number={1},
  pages={103--111},
  year={2019},
  publisher={Springer}
}

@article{deng2019interpreting,
  title={Interpreting tree ensembles with intrees},
  author={Deng, Houtao},
  journal={International Journal of Data Science and Analytics},
  volume={7},
  number={4},
  pages={277--287},
  year={2019},
  publisher={Springer}
}




@article{letham2015interpretable,
  title={Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model},
  author={Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H and Madigan, David and others},
  journal={The Annals of Applied Statistics},
  volume={9},
  number={3},
  pages={1350--1371},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1885--1894},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{russell2019efficient,
  title={Efficient search for diverse coherent explanations},
  author={Russell, Chris},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={20--28},
  year={2019}
}


@article{van2019interpretable,
  title={Interpretable counterfactual explanations guided by prototypes},
  author={Van Looveren, Arnaud and Klaise, Janis},
  journal={arXiv preprint arXiv:1907.02584},
  year={2019}
}


@article{krishnan1999extracting,
  title={Extracting decision trees from trained neural networks},
  author={Krishnan, R and Sivakumar, G and Bhattacharya, P},
  journal={Pattern recognition},
  volume={32},
  number={12},
  year={1999},
  publisher={Elsevier}
}


@inproceedings{boz2002extracting,
  title={Extracting decision trees from trained neural networks},
  author={Boz, Olcay},
  booktitle={Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={456--461},
  year={2002}
}

@article{guidotti2018local,
  title={Local rule-based explanations of black box decision systems},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Pedreschi, Dino and Turini, Franco and Giannotti, Fosca},
  journal={arXiv preprint arXiv:1805.10820},
  year={2018}
}


@inproceedings{hendricks2016generating,
  title={Generating visual explanations},
  author={Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
  booktitle={European Conference on Computer Vision},
  pages={3--19},
  year={2016},
  organization={Springer}
}

@article{harradon2018causal,
  title={Causal learning and explanation of deep neural networks via autoencoded activations},
  author={Harradon, Michael and Druce, Jeff and Ruttenberg, Brian},
  journal={arXiv preprint arXiv:1802.00541},
  year={2018}
}

@inproceedings{schwab2019granger,
  title={Granger-causal attentive mixtures of experts: Learning important features with neural networks},
  author={Schwab, Patrick and Miladinovic, Djordje and Karlen, Walter},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4846--4853},
  year={2019}
}




@article{wang_multi-value_2017,
	title = {Multi-{Value} {Rule} {Sets}},
	urldate = {2020-03-11},
	journal = {arXiv:1710.05257 [cs], NIPS},
	author = {Wang, Tong},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.05257},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Data Structures and Algorithms}
}

@article{letham_interpretable_2015,
	title = {Interpretable classifiers using rules and {Bayesian} analysis: {Building} a better stroke prediction model},
	volume = {9},
	issn = {1932-6157},
	shorttitle = {Interpretable classifiers using rules and {Bayesian} analysis},
	doi = {10.1214/15-AOAS848},
	number = {3},
	urldate = {2020-03-13},
	journal = {The Annals of Applied Statistics},
	author = {Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H. and Madigan, David},
	month = sep,
	year = {2015},
	note = {arXiv: 1511.01644},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Applications},
	pages = {1350--1371},
	annote = {Comment: Published at http://dx.doi.org/10.1214/15-AOAS848 in the Annals of Applied Statistics (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics (http://www.imstat.org)}
}


@article{schwab_granger-causal_2019,
	title = {Granger-{Causal} {Attentive} {Mixtures} of {Experts}: {Learning} {Important} {Features} with {Neural} {Networks}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Granger-{Causal} {Attentive} {Mixtures} of {Experts}},
	doi = {10.1609/aaai.v33i01.33014846},
	urldate = {2020-04-02},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Schwab, Patrick and Miladinovic, Djordje and Karlen, Walter},
	month = jul,
	year = {2019},
	pages = {4846--4853}
}


@article{lipovetsky2001analysis,
  title={Analysis of regression in game theory approach},
  author={Lipovetsky, Stan and Conklin, Michael},
  journal={Applied Stochastic Models in Business and Industry},
  volume={17},
  number={4},
  pages={319--330},
  year={2001},
  publisher={Wiley Online Library}
}

@article{vstrumbelj2014explaining,
  title={Explaining prediction models and individual predictions with feature contributions},
  author={{\v{S}}trumbelj, Erik and Kononenko, Igor},
  journal={Knowledge and information systems},
  volume={41},
  number={3},
  pages={647--665},
  year={2014},
  publisher={Springer}
}

@inproceedings{datta2016algorithmic,
  title={Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems},
  author={Datta, Anupam and Sen, Shayak and Zick, Yair},
  booktitle={2016 IEEE symposium on security and privacy (SP)},
  pages={598--617},
  year={2016},
  organization={IEEE}
}


@article{quinlan1987simplifying,
  title={Simplifying decision trees},
  author={Quinlan, J Ross},
  journal={International journal of man-machine studies},
  volume={27},
  number={3},
  pages={221--234},
  year={1987},
  publisher={Elsevier}
}

@inproceedings{guo2018explaining,
  title={Explaining Deep Learning Models--A Bayesian Non-parametric Approach},
  author={Guo, Wenbo and Huang, Sui and Tao, Yunzhe and Xing, Xinyu and Lin, Lin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4514--4524},
  year={2018}
}

@article{krishnan1999extracting,
  title={Extracting decision trees from trained neural networks},
  author={Krishnan, R and Sivakumar, G and Bhattacharya, P},
  journal={Pattern recognition},
  volume={32},
  number={12},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{tan2018distill,
  title={Distill-and-compare: Auditing black-box models using transparent model distillation},
  author={Tan, Sarah and Caruana, Rich and Hooker, Giles and Lou, Yin},
  booktitle={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={303--310},
  year={2018}
}

@article{altmann2010permutation,
  title={Permutation importance: a corrected feature importance measure},
  author={Altmann, Andr{\'e} and Tolo{\c{s}}i, Laura and Sander, Oliver and Lengauer, Thomas},
  journal={Bioinformatics},
  volume={26},
  number={10},
  pages={1340--1347},
  year={2010},
  publisher={Oxford University Press}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3319--3328},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3145--3153},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in neural information processing systems},
  pages={4765--4774},
  year={2017}
}

@article{guidotti2019factual,
  title={Factual and Counterfactual Explanations for Black Box Decision Making},
  author={Guidotti, Riccardo and Monreale, Anna and Giannotti, Fosca and Pedreschi, Dino and Ruggieri, Salvatore and Turini, Franco},
  journal={IEEE Intelligent Systems},
  year={2019},
  publisher={IEEE}
}

@inproceedings{lakkaraju2016interpretable,
  title={Interpretable decision sets: A joint framework for description and prediction},
  author={Lakkaraju, Himabindu and Bach, Stephen H and Leskovec, Jure},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1675--1684},
  year={2016}
}

@article{jang1993functional,
  title={Functional equivalence between radial basis function networks and fuzzy inference systems},
  author={Jang, J-SR and Sun, C-T},
  journal={IEEE transactions on Neural Networks},
  volume={4},
  number={1},
  pages={156--159},
  year={1993},
  publisher={IEEE}
}

@article{guillaume2001designing,
  title={Designing fuzzy inference systems from data: An interpretability-oriented review},
  author={Guillaume, Serge},
  journal={IEEE Transactions on fuzzy systems},
  volume={9},
  number={3},
  pages={426--443},
  year={2001},
  publisher={IEEE}
}

@article{wang2002self,
  title={Self-adaptive neuro-fuzzy inference systems for classification applications},
  author={Wang, Jeen-Shing and Lee, CS George},
  journal={IEEE Transactions on Fuzzy Systems},
  volume={10},
  number={6},
  pages={790--802},
  year={2002},
  publisher={IEEE}
}


@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}



@Article{electronics8080832,
AUTHOR = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
TITLE = {Machine Learning Interpretability: A Survey on Methods and Metrics},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {832},
URL = {https://www.mdpi.com/2079-9292/8/8/832},
ISSN = {2079-9292},
ABSTRACT = {Machine learning systems are becoming increasingly ubiquitous. These systems&rsquo;s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
DOI = {10.3390/electronics8080832}
}

@article{RN76,
   author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
   title = {A Survey of Methods for Explaining Black Box Models},
   journal = {ACM Computing Surveys},
   volume = {51},
   number = {5},
   pages = {1-42},
   ISSN = {03600300},
   DOI = {10.1145/3236009},
   url = {http://dl.acm.org/citation.cfm?doid=3271482.3236009
https://dl.acm.org/ft_gateway.cfm?id=3236009&type=pdf},
   year = {2018},
   type = {Journal Article}
}


@article{gunning2017explainable,
  title={Explainable artificial intelligence (xai)},
  author={Gunning, David},
  journal={Defense Advanced Research Projects Agency (DARPA), nd Web},
  volume={2},
  year={2017}
}

@inproceedings{Kim2017InterpretabilityBF,
  title={Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)},
  author={Been Kim and Martin Wattenberg and Justin Gilmer and Carrie J. Cai and James Wexler and Fernanda B. Vi{\'e}gas and Rory Sayres},
  booktitle={ICML},
  year={2017}
}



@inproceedings{10.1145/2876034.2876042,
author = {Williams, Joseph Jay and Kim, Juho and Rafferty, Anna and Maldonado, Samuel and Gajos, Krzysztof Z. and Lasecki, Walter S. and Heffernan, Neil},
title = {AXIS: Generating Explanations at Scale with Learnersourcing and Machine Learning},
year = {2016},
isbn = {9781450337267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2876034.2876042},
doi = {10.1145/2876034.2876042},
booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
pages = {379–388},
numpages = {10},
keywords = {machine learning, explanation, learnersourcing, adaptive learning, learning at scale, crowdsourcing},
location = {Edinburgh, Scotland, UK},
series = {L@S ’16}
}

@inproceedings{10.5555/2984093.2984126,
author = {Chang, Jonathan and Boyd-Graber, Jordan and Gerrish, Sean and Wang, Chong and Blei, David M.},
title = {Reading Tea Leaves: How Humans Interpret Topic Models},
year = {2009},
isbn = {9781615679119},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems},
pages = {288–296},
numpages = {9},
location = {Vancouver, British Columbia, Canada},
series = {NIPS’09}
}
  
@ARTICLE{2017arXiv171111279K,
       author = {{Kim}, Been and {Wattenberg}, Martin and {Gilmer}, Justin and
         {Cai}, Carrie and {Wexler}, James and {Viegas}, Fernanda and
         {Sayres}, Rory},
        title = "{Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning},
         year = 2017,
        month = nov,
          eid = {arXiv:1711.11279},
        pages = {arXiv:1711.11279},
archivePrefix = {arXiv},
       eprint = {1711.11279},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171111279K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{RN77,
   author = {Rudin, Cynthia},
   title = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
   journal = {arXiv:1811.10154 [cs, stat]},
   url = {http://arxiv.org/abs/1811.10154
https://arxiv.org/abs/1811.10154},
   year = {2019},
   type = {Journal Article}
}


@article{pearl2019seven,
  title={The seven tools of causal inference, with reflections on machine learning},
  author={Pearl, Judea},
  journal={Communications of the ACM},
  volume={62},
  number={3},
  pages={54--60},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@misc{dowhy,
authors={Sharma, Amit and Kiciman, Emre and others},
title={Do{W}hy: {A Python package for causal inference}},
howpublished={https://github.com/microsoft/dowhy}
year={2019}
}

@misc{chen2020causalml, title={CausalML: Python Package for Causal Machine Learning}, author={Huigang Chen and Totte Harinen and Jeong-Yoon Lee and Mike Yung and Zhenyu Zhao}, year={2020}, eprint={2002.11631}, archivePrefix={arXiv}, primaryClass={cs.CY} }

@misc{econml,
  author={Microsoft Research},
  title={{EconML}: {A Python Package for ML-Based Heterogeneous Treatment Effects Estimation}},
  howpublished={https://github.com/microsoft/EconML},
  note={Version 0.x},
  year={2019}
}
@ARTICLE{2019arXiv190302278K,
       author = {{Kalainathan}, Diviyan and {Goudet}, Olivier},
        title = "{Causal Discovery Toolbox: Uncover causal relationships in Python}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Computation, Statistics - Machine Learning},
         year = 2019,
        month = mar,
          eid = {arXiv:1903.02278},
        pages = {arXiv:1903.02278},
archivePrefix = {arXiv},
       eprint = {1903.02278},
 primaryClass = {stat.CO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190302278K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{RN165,
   author = {Künzel, Sören R. and Sekhon, Jasjeet S. and Bickel, Peter J. and Yu, Bin},
   title = {Metalearners for estimating heterogeneous treatment effects using machine learning},
   journal = {Proceedings of the National Academy of Sciences},
   volume = {116},
   pages = {4156-4165},
   year = {2019},
   type = {Journal Article}
}

@misc{RN199,
   pages = {arXiv:1608.00060},
   month = {July 01, 2016},
   url = {https://ui.adsabs.harvard.edu/abs/2016arXiv160800060C},
   year = {2016},
   type = {Electronic Article}
}

@article{chernozhukov2016double,
  title={Double/debiased machine learning for treatment and causal parameters},
  author={Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
  journal={arXiv preprint arXiv:1608.00060},
  year={2016}
}


@article{oprescu2018orthogonal,
  title={Orthogonal random forest for causal inference},
  author={Oprescu, Miruna and Syrgkanis, Vasilis and Wu, Zhiwei Steven},
  journal={arXiv preprint arXiv:1806.03467},
  year={2018}
}

@article{foster2019orthogonal,
  title={Orthogonal statistical learning},
  author={Foster, Dylan J and Syrgkanis, Vasilis},
  journal={arXiv preprint arXiv:1901.09036},
  year={2019}
}

@book{10.5555/3238230,
author = {Pearl, Judea and Mackenzie, Dana},
title = {The Book of Why: The New Science of Cause and Effect},
year = {2018},
isbn = {046509760X},
publisher = {Basic Books, Inc.},
address = {USA},
edition = {1st}
}


@article {Rungeeaau4996,
	author = {Runge, Jakob and Nowack, Peer and Kretschmer, Marlene and Flaxman, Seth and Sejdinovic, Dino},
	title = {Detecting and quantifying causal associations in large nonlinear time series datasets},
	volume = {5},
	number = {11},
	elocation-id = {eaau4996},
	year = {2019},
	doi = {10.1126/sciadv.aau4996},
	publisher = {American Association for the Advancement of Science},
	URL = {https://advances.sciencemag.org/content/5/11/eaau4996},
	eprint = {https://advances.sciencemag.org/content/5/11/eaau4996.full.pdf},
	journal = {Science Advances}
}


@article{doi:10.1063/1.5025050,
author = {Runge,J. },
title = {Causal network reconstruction from time series: From theoretical assumptions to practical estimation},
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
volume = {28},
number = {7},
pages = {075310},
year = {2018},
doi = {10.1063/1.5025050},

URL = { 
        https://doi.org/10.1063/1.5025050
    
},
eprint = { 
        https://doi.org/10.1063/1.5025050
    
}}


@article{runge2015identifying,
  title={Identifying causal gateways and mediators in complex spatio-temporal systems},
  author={Runge, Jakob and Petoukhov, Vladimir and Donges, Jonathan F and Hlinka, Jaroslav and Jajcay, Nikola and Vejmelka, Martin and Hartman, David and Marwan, Norbert and Palu{\v{s}}, Milan and Kurths, J{\"u}rgen},
  journal={Nature communications},
  volume={6},
  number={1},
  pages={1--10},
  year={2015},
  publisher={Nature Publishing Group}
}


@article{runge2015quantifying,
  title={Quantifying information transfer and mediation along causal pathways in complex systems},
  author={Runge, Jakob},
  journal={Physical Review E},
  volume={92},
  number={6},
  pages={062829},
  year={2015},
  publisher={APS}
}

@article{runge2017conditional,
  title={Conditional independence testing based on a nearest-neighbor estimator of conditional mutual information},
  author={Runge, Jakob},
  journal={arXiv preprint arXiv:1709.01447},
  year={2017}
}

@ARTICLE{2017arXiv170508492Z,
       author = {{Zhao}, Yan and {Fang}, Xiao and {Simchi-Levi}, David},
        title = "{Uplift Modeling with Multiple Treatments and General Response Types}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence},
         year = 2017,
        month = may,
          eid = {arXiv:1705.08492},
        pages = {arXiv:1705.08492},
archivePrefix = {arXiv},
       eprint = {1705.08492},
 primaryClass = {cs.AI},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170508492Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{radcliffe2011real,
  title={Real-world uplift modelling with significance-based uplift trees},
  author={Radcliffe, Nicholas J and Surry, Patrick D},
  journal={White Paper TR-2011-1, Stochastic Solutions},
  pages={1--33},
  year={2011},
  publisher={Citeseer}
}

@inproceedings{xian2019reinforcement,
  title={Reinforcement knowledge graph reasoning for explainable recommendation},
  author={Xian, Yikun and Fu, Zuohui and Muthukrishnan, S and De Melo, Gerard and Zhang, Yongfeng},
  booktitle={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={285--294},
  year={2019}
}

@article{dehejia2002propensity,
  title={Propensity score-matching methods for nonexperimental causal studies},
  author={Dehejia, Rajeev H and Wahba, Sadek},
  journal={Review of Economics and statistics},
  volume={84},
  number={1},
  pages={151--161},
  year={2002},
  publisher={MIT Press}
}

@article{frangakis2002principal,
  title={Principal stratification in causal inference},
  author={Frangakis, Constantine E and Rubin, Donald B},
  journal={Biometrics},
  volume={58},
  number={1},
  pages={21--29},
  year={2002},
  publisher={Wiley Online Library}
}

@inproceedings{ustun2019actionable,
  title={Actionable recourse in linear classification},
  author={Ustun, Berk and Spangher, Alexander and Liu, Yang},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={10--19},
  year={2019}
}

@inproceedings{poyiadzi2020face,
  title={FACE: Feasible and actionable counterfactual explanations},
  author={Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={344--350},
  year={2020}
}




@article{article_causal,
author = {Pearl, Judea},
year = {2009},
month = {01},
pages = {96-146},
title = {Causal Inference in Statistics: An Overview},
volume = {3},
journal = {Statistics Surveys},
doi = {10.1214/09-SS057}
}

  
@article{bau2018gan,
  title={Gan dissection: Visualizing and understanding generative adversarial networks},
  author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Zhou, Bolei and Tenenbaum, Joshua B and Freeman, William T and Torralba, Antonio},
  journal={arXiv preprint arXiv:1811.10597},
  year={2018}
}

@article{madumal2019explainable,
  title={Explainable reinforcement learning through a causal lens},
  author={Madumal, Prashan and Miller, Tim and Sonenberg, Liz and Vetere, Frank},
  journal={arXiv preprint arXiv:1905.10958},
  year={2019}
}

@article{alvarez2017causal,
  title={A causal framework for explaining the predictions of black-box sequence-to-sequence models},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1707.01943},
  year={2017}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@article{goldstein2015peeking,
  title={Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation},
  author={Goldstein, Alex and Kapelner, Adam and Bleich, Justin and Pitkin, Emil},
  journal={Journal of Computational and Graphical Statistics},
  volume={24},
  number={1},
  pages={44--65},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{zhao2019causal,
  title={Causal interpretations of black-box models},
  author={Zhao, Qingyuan and Hastie, Trevor},
  journal={Journal of Business \& Economic Statistics},
  pages={1--10},
  year={2019},
  publisher={Taylor \& Francis}
}


@article{doi:10.1080/07350015.2019.1624293,
author = {Qingyuan Zhao and Trevor Hastie},
title = {Causal Interpretations of Black-Box Models},
journal = {Journal of Business \& Economic Statistics},
volume = {0},
number = {0},
pages = {1-10},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/07350015.2019.1624293},

URL = { 
        https://doi.org/10.1080/07350015.2019.1624293
    
},
eprint = { 
        https://doi.org/10.1080/07350015.2019.1624293
    
}}


@ARTICLE{2019arXiv190108162D,
       author = {{Dasgupta}, Ishita and {Wang}, Jane and {Chiappa}, Silvia and
         {Mitrovic}, Jovana and {Ortega}, Pedro and {Raposo}, David and
         {Hughes}, Edward and {Battaglia}, Peter and {Botvinick}, Matthew and
         {Kurth-Nelson}, Zeb},
        title = "{Causal Reasoning from Meta-reinforcement Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = 2019,
        month = jan,
          eid = {arXiv:1901.08162},
        pages = {arXiv:1901.08162},
archivePrefix = {arXiv},
       eprint = {1901.08162},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190108162D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



