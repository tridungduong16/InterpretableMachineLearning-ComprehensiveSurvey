{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/dtd/.conda/envs/phd_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import os, sys\n",
    "import sys\n",
    "sys.path.insert(1, '/home/dtd/Documents/interpretable_machine_learning/Source Code/my_work/lib')\n",
    "sys.path.insert(1, '/home/dtd/Documents/interpretable_machine_learning/Causal Inference/CEA')\n",
    "import loader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import dowhy.datasets\n",
    "import dowhy\n",
    "import propensity_score_estimator as pse\n",
    "import incremental_ps_score_estimator as ipse\n",
    "import math \n",
    "import timeit\n",
    "import evaluation as evl\n",
    "\n",
    "from scipy.stats import sem\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from econml.dml import LinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV\n",
    "from econml.inference import BootstrapInference\n",
    "from econml.dml import SparseLinearDMLCateEstimator\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Inputs\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data viz\n",
    "from mlens.visualization import corr_X_y, corrmat\n",
    "\n",
    "# Model evaluation\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "\n",
    "# Ensemble\n",
    "from mlens.ensemble import SuperLearner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-1000.train.npz\"\n",
    "PATH_TEST = \"/home/dtd/Documents/interpretable_machine_learning/Source Code/data/ihdp_npci_1-1000.test.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, i_exp):\n",
    "    col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "    cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "    col = col + cov\n",
    "    features = cov + [\"t\"] \n",
    "    D = np.load(path)\n",
    "    df = pd.DataFrame(columns=col)\n",
    "\n",
    "    for i in range(1,26):\n",
    "        df['x' + str(i)]  = D['x'][:,i-1,i_exp-1]\n",
    "\n",
    "    df['t']  = D['t'][:,i_exp-1:i_exp]\n",
    "    df['yf'] = D['yf'][:,i_exp-1:i_exp]\n",
    "    df['ycf'] = D['ycf'][:,i_exp-1:i_exp]\n",
    "    df['mu0'] = D['mu0'][:,i_exp-1:i_exp]\n",
    "    df['mu1'] = D['mu1'][:,i_exp-1:i_exp]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 't'\n",
    "outcome = 'yf'\n",
    "col =  [\"t\", \"yf\", \"ycf\", \"mu0\", \"mu1\" ]\n",
    "cov = [\"x\" + str(i) for i in range(1,26)]\n",
    "col = col + cov\n",
    "features = cov + [\"t\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data(PATH_TRAIN, 40)\n",
    "data_test  = load_data(PATH_TEST, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>yf</th>\n",
       "      <th>ycf</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.881007</td>\n",
       "      <td>10.152449</td>\n",
       "      <td>4.124143</td>\n",
       "      <td>11.114897</td>\n",
       "      <td>1.159618</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.733261</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>-0.360940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.191785</td>\n",
       "      <td>11.010013</td>\n",
       "      <td>4.631141</td>\n",
       "      <td>11.230842</td>\n",
       "      <td>-0.504825</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>0.558638</td>\n",
       "      <td>-0.692171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.657644</td>\n",
       "      <td>9.277814</td>\n",
       "      <td>8.799111</td>\n",
       "      <td>11.872689</td>\n",
       "      <td>-0.137351</td>\n",
       "      <td>0.196818</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>1.746464</td>\n",
       "      <td>0.135907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.054683</td>\n",
       "      <td>12.153734</td>\n",
       "      <td>18.181274</td>\n",
       "      <td>12.598431</td>\n",
       "      <td>0.208507</td>\n",
       "      <td>0.996346</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.504155</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.729148</td>\n",
       "      <td>10.984696</td>\n",
       "      <td>4.917858</td>\n",
       "      <td>11.290912</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-1.337276</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>0.301522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t         yf        ycf        mu0        mu1        x1        x2  \\\n",
       "0  0.0   4.881007  10.152449   4.124143  11.114897  1.159618 -0.202946   \n",
       "1  0.0   4.191785  11.010013   4.631141  11.230842 -0.504825 -0.202946   \n",
       "2  1.0  11.657644   9.277814   8.799111  11.872689 -0.137351  0.196818   \n",
       "3  0.0  18.054683  12.153734  18.181274  12.598431  0.208507  0.996346   \n",
       "4  0.0   6.729148  10.984696   4.917858  11.290912 -1.045229 -1.337276   \n",
       "\n",
       "         x3        x4        x5        x6   x7   x8   x9  x10  x11  x12  x13  \\\n",
       "0 -0.733261 -0.879606  0.808706 -0.360940  0.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
       "1  0.011465  2.244320  0.558638 -0.692171  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "2  0.011465  2.244320  1.746464  0.135907  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "3  1.128554  0.161703 -0.504155  1.129600  1.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "4  1.128554 -0.879606  0.683672  0.301522  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   x14  x15  x16  x17  x18  x19  x20  x21  x22  x23  x24  x25  \n",
       "0  2.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  1.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4  2.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_feature = [\"x\" + str(a) for a in range(1,7)]\n",
    "cat_feature = [\"x\" + str(a) for a in range(7, 26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# data_test[con_feature] = scaler.fit_transform(data_test[con_feature])\n",
    "# data_train[con_feature] = scaler.fit_transform(data_train[con_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 2.5\n",
    "features = cov.copy()\n",
    "features.append(treatment)\n",
    "\n",
    "## Fit treatment\n",
    "model_t = RandomForestClassifier(n_estimators=10)\n",
    "model_t.fit(data_train[cov], data_train[treatment])\n",
    "\n",
    "## Fit outcome\n",
    "model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "model_y.fit(data_train[features], data_train[outcome])\n",
    "\n",
    "## Compute propensity score\n",
    "data_test['p1'] = model_t.predict_proba(data_test[cov])[:,1]\n",
    "data_test['p0'] = 1 - data_test['p1']\n",
    "\n",
    "## fit outcome\n",
    "data_test['predicted_y'] = model_y.predict(data_test[features])\n",
    "\n",
    "## Compute counterfactual outcome with no treatment\n",
    "data_pos = data_test.copy()\n",
    "data_pos[treatment] = 1\n",
    "data_test['cf1'] = model_y.predict(data_pos[features])\n",
    "\n",
    "## Compute counterfactual outcome with treatment\n",
    "data_neg = data_test.copy()\n",
    "data_neg[treatment] = 0\n",
    "data_test['cf0'] = model_y.predict(data_neg[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fit treatment\n",
    "# model_t = LogisticRegression()\n",
    "# model_t.fit(data_train[cov], data_train[treatment])\n",
    "\n",
    "# data_train['p1'] = model_t.predict_proba(data_train[cov])[:,0]\n",
    "# data_train['p0'] = 1 - data_train['p1']\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "# clf.fit(data_train[cov], data_train[treatment])\n",
    "\n",
    "# y_pred=clf.predict(data_train[cov])\n",
    "\n",
    "# data_train['p1'] = clf.predict_proba(data_train[cov])[:,1]\n",
    "# data_train['p0'] = 1 - data_train['p1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    546\n",
       "1.0    126\n",
       "Name: t, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.t.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t.predict(data_train[cov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(model_t.predict(data_test[cov]), data_test[treatment]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incremental propensity score:**\n",
    "$$q_1 = \\frac{\\delta p_0}{\\delta p_0 + p_1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute incremental score \n",
    "data_test['q1'] = (delta * data_test['p1']) / (delta * data_test['p1'] + data_test['p0'])\n",
    "data_test['q0'] = 1 - data_test['q1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimator:**\n",
    "$$\\Psi (\\delta ) = q1*\\mathbb{E}[Y | X,A=1] + q_0*\\mathbb{E}[Y | X,A=0]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_estimator = data_test['q1']*data_test['cf1'] + data_test['q0']*data_test['cf0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_estimator_2 = (delta*data_test[treatment] + 1 - data_test[treatment])*data_test[outcome] / (\n",
    "    delta*data_test['p1'] + data_test['p0']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = data_test.shape[0]\n",
    "data_test['ips_weight'] = (1/num_units) * (\n",
    "    data_test[treatment] / data_test['p1'] + (1 - data_test[treatment]) / (1 - data_test['p1'])\n",
    ")\n",
    "\n",
    "# Calculating the effect\n",
    "data_test['d_y'] = (\n",
    "    data_test['ips_weight'] *\n",
    "    data_test[treatment] *\n",
    "    data_test[outcome]\n",
    ")\n",
    "data_test['dbar_y'] = (\n",
    "    data_test['ips_weight'] *\n",
    "    (1 - data_test[treatment]) *\n",
    "    data_test[outcome]\n",
    ")\n",
    "weighting_estimator  = data_test['d_y'] - data_test['dbar_y']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence function** $\\mathbb{1}$\n",
    "\n",
    "$$ q_0*\\phi_0 + q_1*\\phi_1 + \\frac{\\delta*(\\mu(X,1) - \\mu(X,0)*(A - p_1)}{(\\delta*p_1 + p_0)^2} - \\Psi (\\delta )$$ \n",
    "\n",
    "$$\\phi_a = \\frac{\\mathbb{1}(A=a)}{\\pi(a|x)}(Y - \\mu(X,A)) +  \\mu(X,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['predicted_t'] = model_t.predict(data_test[cov])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y - mu(X,A)\n",
    "residual = data_test[outcome] - data_test['predicted_y']\n",
    "\n",
    "w0 = [0 if data_test.loc[i,'predicted_t'] == 1 else 1/data_test.loc[i, 'p0'] for i in range(len(data_test))]\n",
    "w1 = [0 if data_test.loc[i,'predicted_t'] == 0 else 1/data_test.loc[i, 'p1'] for i in range(len(data_test))]\n",
    "w0 = np.array(w0)\n",
    "w1 = np.array(w1)\n",
    "\n",
    "phi_0 = w0 * residual + data_test['cf0'] \n",
    "phi_1 = w1 * residual + data_test['cf1']\n",
    "\n",
    "avg_phi = data_test['q1']*phi_1 + data_test['q0']*phi_0\n",
    "\n",
    "diff_cf = data_test['cf1'] - data_test['cf0']\n",
    "diff_ps = data_test[treatment] - data_test['p1']\n",
    "modi_ps = (delta*data_test['p1'] + data_test['p0'])**2\n",
    "\n",
    "avg_diff = (delta*diff_cf*diff_ps) / modi_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test['w0'] = [0 if data_test.loc[i,treatment] == 1 else 1/data_test.loc[i, 'p0'] for i in range(len(data_test))]\n",
    "# data_test['w1'] = [0 if data_test.loc[i,treatment] == 0 else 1/data_test.loc[i, 'p1'] for i in range(len(data_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test[['p0', 'p1', 'w0', 'w1', 't']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w0, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test[['t', 'p0', 'p1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True effect: 3.511+-0.594\n"
     ]
    }
   ],
   "source": [
    "true_effect = data_test['mu1'] - data_test['mu0']\n",
    "means, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "print('True effect: {:.3f}+-{:.3f}'.format(means, stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = avg_phi + avg_diff - simple_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation effect: 0.307+-0.400\n"
     ]
    }
   ],
   "source": [
    "means, stds = np.mean(influence, axis=0), sem(influence, axis=0)\n",
    "print('Estimation effect: {:.3f}+-{:.3f}'.format(means, stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yf</th>\n",
       "      <th>cf0</th>\n",
       "      <th>cf1</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>t</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>predicted_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.693778</td>\n",
       "      <td>2.768257</td>\n",
       "      <td>10.287870</td>\n",
       "      <td>2.768257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.388813</td>\n",
       "      <td>6.789495</td>\n",
       "      <td>10.043943</td>\n",
       "      <td>10.043943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.559540</td>\n",
       "      <td>5.348458</td>\n",
       "      <td>10.218338</td>\n",
       "      <td>5.348458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.413086</td>\n",
       "      <td>13.204406</td>\n",
       "      <td>14.240686</td>\n",
       "      <td>13.204406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.180642</td>\n",
       "      <td>8.503391</td>\n",
       "      <td>12.769866</td>\n",
       "      <td>8.503391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.526179</td>\n",
       "      <td>9.957633</td>\n",
       "      <td>13.718344</td>\n",
       "      <td>9.957633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.417452</td>\n",
       "      <td>2.922498</td>\n",
       "      <td>10.815050</td>\n",
       "      <td>2.922498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.485668</td>\n",
       "      <td>8.318328</td>\n",
       "      <td>12.575033</td>\n",
       "      <td>8.318328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.837117</td>\n",
       "      <td>3.068015</td>\n",
       "      <td>9.587836</td>\n",
       "      <td>3.068015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.663785</td>\n",
       "      <td>8.178124</td>\n",
       "      <td>13.315039</td>\n",
       "      <td>8.178124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.663746</td>\n",
       "      <td>2.264391</td>\n",
       "      <td>10.196753</td>\n",
       "      <td>10.196753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.468940</td>\n",
       "      <td>2.568161</td>\n",
       "      <td>10.749387</td>\n",
       "      <td>2.568161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.589395</td>\n",
       "      <td>5.110171</td>\n",
       "      <td>10.009879</td>\n",
       "      <td>5.110171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.774169</td>\n",
       "      <td>4.981305</td>\n",
       "      <td>9.229074</td>\n",
       "      <td>4.981305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.622125</td>\n",
       "      <td>7.801469</td>\n",
       "      <td>10.834283</td>\n",
       "      <td>10.834283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.048188</td>\n",
       "      <td>12.804811</td>\n",
       "      <td>15.513094</td>\n",
       "      <td>15.513094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.727600</td>\n",
       "      <td>7.288948</td>\n",
       "      <td>11.640967</td>\n",
       "      <td>7.288948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27.416925</td>\n",
       "      <td>17.572930</td>\n",
       "      <td>15.145603</td>\n",
       "      <td>17.572930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.355411</td>\n",
       "      <td>4.519076</td>\n",
       "      <td>11.477089</td>\n",
       "      <td>4.519076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.681486</td>\n",
       "      <td>3.581899</td>\n",
       "      <td>9.646569</td>\n",
       "      <td>3.581899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.551120</td>\n",
       "      <td>14.238890</td>\n",
       "      <td>14.370892</td>\n",
       "      <td>14.370892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.182991</td>\n",
       "      <td>5.150390</td>\n",
       "      <td>11.275965</td>\n",
       "      <td>5.150390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.085123</td>\n",
       "      <td>1.659583</td>\n",
       "      <td>9.519810</td>\n",
       "      <td>1.659583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.388762</td>\n",
       "      <td>1.675240</td>\n",
       "      <td>9.321025</td>\n",
       "      <td>1.675240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.805091</td>\n",
       "      <td>8.146203</td>\n",
       "      <td>11.422079</td>\n",
       "      <td>8.146203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.039507</td>\n",
       "      <td>12.303455</td>\n",
       "      <td>13.952745</td>\n",
       "      <td>13.952745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.794559</td>\n",
       "      <td>9.916600</td>\n",
       "      <td>11.236499</td>\n",
       "      <td>9.916600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.476144</td>\n",
       "      <td>21.923027</td>\n",
       "      <td>21.410696</td>\n",
       "      <td>21.923027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.643435</td>\n",
       "      <td>7.661441</td>\n",
       "      <td>12.143772</td>\n",
       "      <td>7.661441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.359184</td>\n",
       "      <td>3.825276</td>\n",
       "      <td>9.215303</td>\n",
       "      <td>3.825276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>22.849701</td>\n",
       "      <td>22.446980</td>\n",
       "      <td>21.634286</td>\n",
       "      <td>22.446980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.465685</td>\n",
       "      <td>3.880689</td>\n",
       "      <td>11.416541</td>\n",
       "      <td>11.416541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.842551</td>\n",
       "      <td>7.315155</td>\n",
       "      <td>11.535701</td>\n",
       "      <td>7.315155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.223383</td>\n",
       "      <td>12.810081</td>\n",
       "      <td>14.528976</td>\n",
       "      <td>12.810081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.870018</td>\n",
       "      <td>8.423931</td>\n",
       "      <td>13.396011</td>\n",
       "      <td>8.423931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17.342890</td>\n",
       "      <td>16.841840</td>\n",
       "      <td>17.373202</td>\n",
       "      <td>16.841840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9.949914</td>\n",
       "      <td>7.646051</td>\n",
       "      <td>10.584305</td>\n",
       "      <td>7.646051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17.289566</td>\n",
       "      <td>14.438862</td>\n",
       "      <td>16.716141</td>\n",
       "      <td>14.438862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.460387</td>\n",
       "      <td>3.358531</td>\n",
       "      <td>11.151760</td>\n",
       "      <td>3.358531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.076507</td>\n",
       "      <td>2.323926</td>\n",
       "      <td>10.184876</td>\n",
       "      <td>2.323926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.755930</td>\n",
       "      <td>4.951572</td>\n",
       "      <td>10.898817</td>\n",
       "      <td>4.951572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.350628</td>\n",
       "      <td>2.802827</td>\n",
       "      <td>9.669911</td>\n",
       "      <td>2.802827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6.478985</td>\n",
       "      <td>5.208404</td>\n",
       "      <td>10.452922</td>\n",
       "      <td>5.208404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.358083</td>\n",
       "      <td>6.316361</td>\n",
       "      <td>10.801386</td>\n",
       "      <td>6.316361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8.662672</td>\n",
       "      <td>7.107938</td>\n",
       "      <td>12.501965</td>\n",
       "      <td>7.107938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8.586178</td>\n",
       "      <td>8.745464</td>\n",
       "      <td>12.389358</td>\n",
       "      <td>8.745464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.283682</td>\n",
       "      <td>4.990119</td>\n",
       "      <td>9.635759</td>\n",
       "      <td>4.990119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.314802</td>\n",
       "      <td>8.339541</td>\n",
       "      <td>11.429801</td>\n",
       "      <td>8.339541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>11.703409</td>\n",
       "      <td>6.866168</td>\n",
       "      <td>10.594855</td>\n",
       "      <td>10.594855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>12.972204</td>\n",
       "      <td>9.852362</td>\n",
       "      <td>12.301473</td>\n",
       "      <td>9.852362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10.210860</td>\n",
       "      <td>7.370384</td>\n",
       "      <td>12.920636</td>\n",
       "      <td>7.370384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>13.386629</td>\n",
       "      <td>10.207584</td>\n",
       "      <td>12.782858</td>\n",
       "      <td>10.207584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>12.084831</td>\n",
       "      <td>11.345516</td>\n",
       "      <td>13.040588</td>\n",
       "      <td>13.040588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.755621</td>\n",
       "      <td>6.773246</td>\n",
       "      <td>10.941154</td>\n",
       "      <td>6.773246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3.627388</td>\n",
       "      <td>1.611858</td>\n",
       "      <td>9.867941</td>\n",
       "      <td>1.611858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>12.185609</td>\n",
       "      <td>9.912747</td>\n",
       "      <td>12.576548</td>\n",
       "      <td>12.576548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.329539</td>\n",
       "      <td>5.330096</td>\n",
       "      <td>10.479633</td>\n",
       "      <td>5.330096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3.197591</td>\n",
       "      <td>1.011031</td>\n",
       "      <td>8.732330</td>\n",
       "      <td>1.011031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>12.678079</td>\n",
       "      <td>8.913088</td>\n",
       "      <td>12.323624</td>\n",
       "      <td>12.323624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>8.454586</td>\n",
       "      <td>7.580279</td>\n",
       "      <td>11.318942</td>\n",
       "      <td>7.580279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>12.535349</td>\n",
       "      <td>5.100130</td>\n",
       "      <td>9.494562</td>\n",
       "      <td>9.494562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11.517468</td>\n",
       "      <td>9.246351</td>\n",
       "      <td>11.506518</td>\n",
       "      <td>9.246351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5.831840</td>\n",
       "      <td>5.509072</td>\n",
       "      <td>11.403817</td>\n",
       "      <td>5.509072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.836147</td>\n",
       "      <td>5.379472</td>\n",
       "      <td>9.577053</td>\n",
       "      <td>5.379472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8.720603</td>\n",
       "      <td>9.205773</td>\n",
       "      <td>12.282408</td>\n",
       "      <td>9.205773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2.482181</td>\n",
       "      <td>3.137404</td>\n",
       "      <td>10.048787</td>\n",
       "      <td>3.137404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>13.184634</td>\n",
       "      <td>8.870491</td>\n",
       "      <td>12.406641</td>\n",
       "      <td>8.870491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.189634</td>\n",
       "      <td>2.210814</td>\n",
       "      <td>9.288468</td>\n",
       "      <td>2.210814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.239632</td>\n",
       "      <td>4.094398</td>\n",
       "      <td>9.834971</td>\n",
       "      <td>4.094398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.358277</td>\n",
       "      <td>4.384314</td>\n",
       "      <td>11.585546</td>\n",
       "      <td>4.384314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.026786</td>\n",
       "      <td>5.259959</td>\n",
       "      <td>11.180002</td>\n",
       "      <td>5.259959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.214244</td>\n",
       "      <td>6.442326</td>\n",
       "      <td>10.826949</td>\n",
       "      <td>6.442326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3.992819</td>\n",
       "      <td>2.015018</td>\n",
       "      <td>9.153047</td>\n",
       "      <td>2.015018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4.959892</td>\n",
       "      <td>8.619622</td>\n",
       "      <td>12.816542</td>\n",
       "      <td>8.619622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>13.227158</td>\n",
       "      <td>7.814415</td>\n",
       "      <td>10.377012</td>\n",
       "      <td>10.377012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           yf        cf0        cf1  predicted_y    t   p0   p1  predicted_t\n",
       "0    2.693778   2.768257  10.287870     2.768257  0.0  1.0  0.0          0.0\n",
       "1   12.388813   6.789495  10.043943    10.043943  1.0  0.7  0.3          0.0\n",
       "2    5.559540   5.348458  10.218338     5.348458  0.0  0.9  0.1          0.0\n",
       "3   15.413086  13.204406  14.240686    13.204406  0.0  0.8  0.2          0.0\n",
       "4    9.180642   8.503391  12.769866     8.503391  0.0  0.9  0.1          0.0\n",
       "5    8.526179   9.957633  13.718344     9.957633  0.0  0.9  0.1          0.0\n",
       "6    3.417452   2.922498  10.815050     2.922498  0.0  1.0  0.0          0.0\n",
       "7    7.485668   8.318328  12.575033     8.318328  0.0  0.8  0.2          0.0\n",
       "8    3.837117   3.068015   9.587836     3.068015  0.0  0.9  0.1          0.0\n",
       "9    9.663785   8.178124  13.315039     8.178124  0.0  0.9  0.1          0.0\n",
       "10   9.663746   2.264391  10.196753    10.196753  1.0  1.0  0.0          0.0\n",
       "11   3.468940   2.568161  10.749387     2.568161  0.0  0.8  0.2          0.0\n",
       "12   4.589395   5.110171  10.009879     5.110171  0.0  1.0  0.0          0.0\n",
       "13   7.774169   4.981305   9.229074     4.981305  0.0  0.8  0.2          0.0\n",
       "14  10.622125   7.801469  10.834283    10.834283  1.0  0.8  0.2          0.0\n",
       "15  13.048188  12.804811  15.513094    15.513094  1.0  0.4  0.6          1.0\n",
       "16   6.727600   7.288948  11.640967     7.288948  0.0  1.0  0.0          0.0\n",
       "17  27.416925  17.572930  15.145603    17.572930  0.0  0.9  0.1          0.0\n",
       "18   1.355411   4.519076  11.477089     4.519076  0.0  0.7  0.3          0.0\n",
       "19   2.681486   3.581899   9.646569     3.581899  0.0  1.0  0.0          0.0\n",
       "20  13.551120  14.238890  14.370892    14.370892  1.0  0.9  0.1          0.0\n",
       "21   4.182991   5.150390  11.275965     5.150390  0.0  0.9  0.1          0.0\n",
       "22   5.085123   1.659583   9.519810     1.659583  0.0  1.0  0.0          0.0\n",
       "23   3.388762   1.675240   9.321025     1.675240  0.0  1.0  0.0          0.0\n",
       "24  10.805091   8.146203  11.422079     8.146203  0.0  0.9  0.1          0.0\n",
       "25  12.039507  12.303455  13.952745    13.952745  1.0  0.9  0.1          0.0\n",
       "26  10.794559   9.916600  11.236499     9.916600  0.0  0.6  0.4          0.0\n",
       "27  32.476144  21.923027  21.410696    21.923027  0.0  0.8  0.2          0.0\n",
       "28   8.643435   7.661441  12.143772     7.661441  0.0  1.0  0.0          0.0\n",
       "29   3.359184   3.825276   9.215303     3.825276  0.0  1.0  0.0          0.0\n",
       "30  22.849701  22.446980  21.634286    22.446980  0.0  0.8  0.2          0.0\n",
       "31  10.465685   3.880689  11.416541    11.416541  1.0  0.8  0.2          0.0\n",
       "32   7.842551   7.315155  11.535701     7.315155  0.0  0.8  0.2          0.0\n",
       "33  12.223383  12.810081  14.528976    12.810081  0.0  0.7  0.3          0.0\n",
       "34   9.870018   8.423931  13.396011     8.423931  0.0  0.9  0.1          0.0\n",
       "35  17.342890  16.841840  17.373202    16.841840  0.0  0.6  0.4          0.0\n",
       "36   9.949914   7.646051  10.584305     7.646051  0.0  0.9  0.1          0.0\n",
       "37  17.289566  14.438862  16.716141    14.438862  0.0  0.8  0.2          0.0\n",
       "38   2.460387   3.358531  11.151760     3.358531  0.0  0.9  0.1          0.0\n",
       "39   1.076507   2.323926  10.184876     2.323926  0.0  1.0  0.0          0.0\n",
       "40   4.755930   4.951572  10.898817     4.951572  0.0  0.9  0.1          0.0\n",
       "41   5.350628   2.802827   9.669911     2.802827  0.0  1.0  0.0          0.0\n",
       "42   6.478985   5.208404  10.452922     5.208404  0.0  0.7  0.3          0.0\n",
       "43   6.358083   6.316361  10.801386     6.316361  0.0  0.5  0.5          0.0\n",
       "44   8.662672   7.107938  12.501965     7.107938  0.0  0.4  0.6          1.0\n",
       "45   8.586178   8.745464  12.389358     8.745464  0.0  0.7  0.3          0.0\n",
       "46   5.283682   4.990119   9.635759     4.990119  0.0  0.6  0.4          0.0\n",
       "47   7.314802   8.339541  11.429801     8.339541  0.0  0.6  0.4          0.0\n",
       "48  11.703409   6.866168  10.594855    10.594855  1.0  1.0  0.0          0.0\n",
       "49  12.972204   9.852362  12.301473     9.852362  0.0  0.8  0.2          0.0\n",
       "50  10.210860   7.370384  12.920636     7.370384  0.0  0.7  0.3          0.0\n",
       "51  13.386629  10.207584  12.782858    10.207584  0.0  1.0  0.0          0.0\n",
       "52  12.084831  11.345516  13.040588    13.040588  1.0  0.6  0.4          0.0\n",
       "53   5.755621   6.773246  10.941154     6.773246  0.0  0.8  0.2          0.0\n",
       "54   3.627388   1.611858   9.867941     1.611858  0.0  1.0  0.0          0.0\n",
       "55  12.185609   9.912747  12.576548    12.576548  1.0  0.8  0.2          0.0\n",
       "56   6.329539   5.330096  10.479633     5.330096  0.0  0.9  0.1          0.0\n",
       "57   3.197591   1.011031   8.732330     1.011031  0.0  0.9  0.1          0.0\n",
       "58  12.678079   8.913088  12.323624    12.323624  1.0  0.6  0.4          0.0\n",
       "59   8.454586   7.580279  11.318942     7.580279  0.0  0.9  0.1          0.0\n",
       "60  12.535349   5.100130   9.494562     9.494562  1.0  0.9  0.1          0.0\n",
       "61  11.517468   9.246351  11.506518     9.246351  0.0  0.5  0.5          0.0\n",
       "62   5.831840   5.509072  11.403817     5.509072  0.0  0.8  0.2          0.0\n",
       "63   4.836147   5.379472   9.577053     5.379472  0.0  0.9  0.1          0.0\n",
       "64   8.720603   9.205773  12.282408     9.205773  0.0  1.0  0.0          0.0\n",
       "65   2.482181   3.137404  10.048787     3.137404  0.0  0.7  0.3          0.0\n",
       "66  13.184634   8.870491  12.406641     8.870491  0.0  0.9  0.1          0.0\n",
       "67   2.189634   2.210814   9.288468     2.210814  0.0  0.6  0.4          0.0\n",
       "68   4.239632   4.094398   9.834971     4.094398  0.0  0.7  0.3          0.0\n",
       "69   1.358277   4.384314  11.585546     4.384314  0.0  1.0  0.0          0.0\n",
       "70   3.026786   5.259959  11.180002     5.259959  0.0  1.0  0.0          0.0\n",
       "71   7.214244   6.442326  10.826949     6.442326  0.0  0.7  0.3          0.0\n",
       "72   3.992819   2.015018   9.153047     2.015018  0.0  0.9  0.1          0.0\n",
       "73   4.959892   8.619622  12.816542     8.619622  0.0  0.8  0.2          0.0\n",
       "74  13.227158   7.814415  10.377012    10.377012  1.0  0.8  0.2          0.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[['yf', 'cf0', 'cf1', 'predicted_y', 't', 'p0', 'p1', 'predicted_t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test[data_test.t == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-29e0c3615294>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-29e0c3615294>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_influence_function(delta, data_train, data_test):\n",
    "    features = cov.copy()\n",
    "    features.append(treatment)\n",
    "\n",
    "    ## Fit treatment\n",
    "    model_t = RandomForestClassifier(n_estimators=10)\n",
    "    model_t.fit(data_train[cov], data_train[treatment])\n",
    "\n",
    "    ## Fit outcome\n",
    "    ## model_y = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    ## model_y.fit(data_train[features], data_train[outcome])\n",
    "    \n",
    "    data_train_treated = data_train[data_train[treatment] == 1]\n",
    "    data_train_control = data_train[data_train[treatment] == 0]\n",
    "    \n",
    "    model_y_treated = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y_treated.fit(data_train_treated[cov], data_train_treated[outcome])\n",
    " \n",
    "    model_y_control = GradientBoostingRegressor(random_state=0, n_estimators = 5000)\n",
    "    model_y_control.fit(data_train_control[cov], data_train_control[outcome])\n",
    "    \n",
    "    \n",
    "    ## Compute propensity score\n",
    "    data_test['p1'] = model_t.predict_proba(data_test[cov])[:,1]\n",
    "    data_test['p0'] = 1 - data_test['p1']\n",
    "    \n",
    "    data_test['predicted_y'] = 0\n",
    "\n",
    "    data_test_treated = data_test[data_test[treatment] == 1]\n",
    "    data_test_control = data_test[data_test[treatment] == 0]\n",
    "    \n",
    "    ## fit outcome\n",
    "    data_test.loc[data_test_treated.index.values,'predicted_y'] = model_y_treated.predict(data_test_treated[cov])\n",
    "    data_test.loc[data_test_control.index.values,'predicted_y'] = model_y_control.predict(data_test_control[cov])\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data_test.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data_test['cf1'] = model_y_treated.predict(data_pos[cov])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data_test.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data_test['cf0'] = model_y_control.predict(data_neg[cov])\n",
    "    \n",
    "    ## Compute incremental score \n",
    "    data_test['q1'] = (delta * data_test['p1']) / (delta * data_test['p1'] + data_test['p0'])\n",
    "    data_test['q0'] = 1 - data_test['q1']\n",
    "    estimator = data_test['q1']*data_test['cf1'] + data_test['q0']*data_test['cf0']\n",
    "\n",
    "    # Y - mu(X,A)\n",
    "    residual = data_test[outcome] - data_test['predicted_y']\n",
    "    data_test['predicted_t'] = model_t.predict(data_test[cov])\n",
    "    \n",
    "    print(data_test[['t', 'p0', 'p1']])\n",
    "    \n",
    "    w0 = [0 if data_test.loc[i,'predicted_t'] == 1 else 1/data_test.loc[i, 'p0'] for i in range(len(data_test))]\n",
    "    w1 = [0 if data_test.loc[i,'predicted_t'] == 0 else 1/data_test.loc[i, 'p1'] for i in range(len(data_test))]\n",
    "    w0 = np.array(w0)\n",
    "    w1 = np.array(w1)\n",
    "\n",
    "    phi_0 = w0 * residual + data_test['cf0'] \n",
    "    phi_1 = w1 * residual + data_test['cf1']\n",
    "\n",
    "    avg_phi = data_test['q1']*phi_1 + data_test['q0']*phi_0\n",
    "\n",
    "    diff_cf = data_test['cf1'] - data_test['cf0']\n",
    "    diff_ps = data_test[treatment] - data_test['p1']\n",
    "    modi_ps = (delta*data_test['p1'] + data_test['p0'])**2\n",
    "\n",
    "    avg_diff = (delta*diff_cf*diff_ps) / modi_ps\n",
    "    influence = avg_phi + avg_diff - estimator\n",
    "    return influence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = np.mean(data_test['mu1'] - data_test['mu0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|| 1/1 [00:02<00:00,  2.40s/it]\u001b[A\n",
      "1it [00:02,  2.41s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   p0   p1\n",
      "0   0.0  1.0  0.0\n",
      "1   1.0  0.7  0.3\n",
      "2   0.0  0.7  0.3\n",
      "3   0.0  0.8  0.2\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  0.4  0.6\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  0.8  0.2\n",
      "8   0.0  0.9  0.1\n",
      "9   0.0  0.9  0.1\n",
      "10  1.0  1.0  0.0\n",
      "11  0.0  0.8  0.2\n",
      "12  0.0  1.0  0.0\n",
      "13  0.0  0.4  0.6\n",
      "14  1.0  0.8  0.2\n",
      "15  1.0  0.7  0.3\n",
      "16  0.0  1.0  0.0\n",
      "17  0.0  0.6  0.4\n",
      "18  0.0  0.9  0.1\n",
      "19  0.0  1.0  0.0\n",
      "20  1.0  0.6  0.4\n",
      "21  0.0  0.8  0.2\n",
      "22  0.0  0.8  0.2\n",
      "23  0.0  1.0  0.0\n",
      "24  0.0  0.9  0.1\n",
      "25  1.0  1.0  0.0\n",
      "26  0.0  0.6  0.4\n",
      "27  0.0  0.8  0.2\n",
      "28  0.0  1.0  0.0\n",
      "29  0.0  1.0  0.0\n",
      "30  0.0  0.6  0.4\n",
      "31  1.0  0.7  0.3\n",
      "32  0.0  0.8  0.2\n",
      "33  0.0  0.7  0.3\n",
      "34  0.0  0.9  0.1\n",
      "35  0.0  0.4  0.6\n",
      "36  0.0  0.5  0.5\n",
      "37  0.0  0.9  0.1\n",
      "38  0.0  0.9  0.1\n",
      "39  0.0  1.0  0.0\n",
      "40  0.0  0.8  0.2\n",
      "41  0.0  1.0  0.0\n",
      "42  0.0  0.8  0.2\n",
      "43  0.0  1.0  0.0\n",
      "44  0.0  0.4  0.6\n",
      "45  0.0  0.7  0.3\n",
      "46  0.0  0.9  0.1\n",
      "47  0.0  0.7  0.3\n",
      "48  1.0  1.0  0.0\n",
      "49  0.0  0.8  0.2\n",
      "50  0.0  0.7  0.3\n",
      "51  0.0  0.8  0.2\n",
      "52  1.0  0.8  0.2\n",
      "53  0.0  0.7  0.3\n",
      "54  0.0  0.9  0.1\n",
      "55  1.0  0.6  0.4\n",
      "56  0.0  0.6  0.4\n",
      "57  0.0  1.0  0.0\n",
      "58  1.0  0.5  0.5\n",
      "59  0.0  0.8  0.2\n",
      "60  1.0  0.5  0.5\n",
      "61  0.0  0.6  0.4\n",
      "62  0.0  1.0  0.0\n",
      "63  0.0  0.8  0.2\n",
      "64  0.0  0.9  0.1\n",
      "65  0.0  0.7  0.3\n",
      "66  0.0  1.0  0.0\n",
      "67  0.0  0.8  0.2\n",
      "68  0.0  1.0  0.0\n",
      "69  0.0  0.9  0.1\n",
      "70  0.0  0.8  0.2\n",
      "71  0.0  0.8  0.2\n",
      "72  0.0  1.0  0.0\n",
      "73  0.0  0.9  0.1\n",
      "74  1.0  0.9  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 1/1 [00:02<00:00,  2.48s/it]\u001b[A\n",
      "2it [00:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   p0   p1\n",
      "0   0.0  1.0  0.0\n",
      "1   1.0  0.8  0.2\n",
      "2   0.0  0.7  0.3\n",
      "3   0.0  0.8  0.2\n",
      "4   0.0  0.8  0.2\n",
      "5   0.0  0.5  0.5\n",
      "6   0.0  0.9  0.1\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  0.6  0.4\n",
      "9   0.0  0.9  0.1\n",
      "10  1.0  0.9  0.1\n",
      "11  0.0  1.0  0.0\n",
      "12  0.0  0.9  0.1\n",
      "13  0.0  1.0  0.0\n",
      "14  1.0  0.8  0.2\n",
      "15  1.0  0.9  0.1\n",
      "16  0.0  0.6  0.4\n",
      "17  0.0  1.0  0.0\n",
      "18  0.0  0.8  0.2\n",
      "19  0.0  1.0  0.0\n",
      "20  1.0  0.9  0.1\n",
      "21  0.0  1.0  0.0\n",
      "22  0.0  0.9  0.1\n",
      "23  0.0  0.8  0.2\n",
      "24  0.0  0.9  0.1\n",
      "25  1.0  0.6  0.4\n",
      "26  0.0  0.6  0.4\n",
      "27  0.0  0.8  0.2\n",
      "28  0.0  1.0  0.0\n",
      "29  0.0  0.9  0.1\n",
      "30  0.0  0.4  0.6\n",
      "31  1.0  0.6  0.4\n",
      "32  0.0  0.6  0.4\n",
      "33  0.0  0.6  0.4\n",
      "34  0.0  0.8  0.2\n",
      "35  0.0  0.8  0.2\n",
      "36  0.0  0.8  0.2\n",
      "37  0.0  0.9  0.1\n",
      "38  0.0  1.0  0.0\n",
      "39  0.0  1.0  0.0\n",
      "40  0.0  0.5  0.5\n",
      "41  0.0  1.0  0.0\n",
      "42  0.0  0.5  0.5\n",
      "43  0.0  0.4  0.6\n",
      "44  0.0  0.5  0.5\n",
      "45  0.0  0.5  0.5\n",
      "46  0.0  0.6  0.4\n",
      "47  0.0  0.7  0.3\n",
      "48  1.0  1.0  0.0\n",
      "49  0.0  0.9  0.1\n",
      "50  0.0  0.6  0.4\n",
      "51  0.0  0.8  0.2\n",
      "52  1.0  0.8  0.2\n",
      "53  0.0  0.6  0.4\n",
      "54  0.0  0.9  0.1\n",
      "55  1.0  0.9  0.1\n",
      "56  0.0  0.6  0.4\n",
      "57  0.0  1.0  0.0\n",
      "58  1.0  0.6  0.4\n",
      "59  0.0  1.0  0.0\n",
      "60  1.0  0.8  0.2\n",
      "61  0.0  0.9  0.1\n",
      "62  0.0  0.9  0.1\n",
      "63  0.0  0.9  0.1\n",
      "64  0.0  0.9  0.1\n",
      "65  0.0  0.8  0.2\n",
      "66  0.0  0.9  0.1\n",
      "67  0.0  0.8  0.2\n",
      "68  0.0  0.7  0.3\n",
      "69  0.0  0.8  0.2\n",
      "70  0.0  1.0  0.0\n",
      "71  0.0  0.6  0.4\n",
      "72  0.0  0.8  0.2\n",
      "73  0.0  1.0  0.0\n",
      "74  1.0  0.7  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "num_of_delta = 1\n",
    "delta_seq = np.linspace(0.5, 5, num_of_delta)\n",
    "\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 1)\n",
    "effect = []\n",
    "fold = 0\n",
    "\n",
    "influence_sample = []\n",
    "for train_index, test_index in tqdm(kf.split(data_train)):\n",
    "    \n",
    "    df_train = data_train.iloc[train_index]\n",
    "    df_test = data_train.iloc[test_index]\n",
    "    \n",
    "    df_train = df_train.reset_index().drop(columns = ['index'])\n",
    "    df_test = df_test.reset_index().drop(columns = ['index'])\n",
    "\n",
    "    \n",
    "    influence_delta = []\n",
    "    \n",
    "    for sample_delta in tqdm(delta_seq):\n",
    "        influence = cal_influence_function(sample_delta, df_train, data_test)\n",
    "        influence_delta.append(np.mean(influence))\n",
    "        \n",
    "    influence_sample.append(np.mean(influence_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle 0.47912842472811346$"
      ],
      "text/plain": [
       "0.47912842472811346"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(influence_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle 3.5105245194250037$"
      ],
      "text/plain": [
       "3.5105245194250037"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate with multiple delta in data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_delta = []\n",
    "delta_seq = np.linspace(1.5, 10, 20)\n",
    " \n",
    "for sample_delta in tqdm(delta_seq):\n",
    "    influence = cal_influence_function(sample_delta, data_train, data_test)\n",
    "    influence_delta.append(np.mean(influence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(influence_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = data_test['mu1'] - data_test['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "print('True effect: {:.3f}+-{:.3f}'.format(means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_influence_function_model(delta, data_train, data_test, model_y, model_t, cov, treatment, outcome):\n",
    "    features = cov.copy()\n",
    "    features.append(treatment)\n",
    "\n",
    "    ## Compute propensity score\n",
    "    data_test['p1'] = model_t.predict_proba(data_test[cov])[:,1]\n",
    "    data_test['p0'] = 1 - data_test['p1']\n",
    "    \n",
    "    ## fit outcome\n",
    "    \n",
    "    data_test['predicted_y'] = model_y.predict(data_test[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with no treatment\n",
    "    data_pos = data_test.copy()\n",
    "    data_pos[treatment] = 1\n",
    "    data_test['treated_cf_outcome'] = model_y.predict(data_pos[features])\n",
    "\n",
    "    ## Compute counterfactual outcome with treatment\n",
    "    data_neg = data_test.copy()\n",
    "    data_neg[treatment] = 0\n",
    "    data_test['control_cf_outcome'] = model_y.predict(data_neg[features])\n",
    "    \n",
    "    ## Compute incremental score \n",
    "    data_test['q1'] = (delta * data_test['p1']) / (delta * data_test['p1'] + data_test['p0'])\n",
    "    data_test['q0'] = 1 - data_test['q1']\n",
    "    estimator = data_test['q1']*data_test['treated_cf_outcome'] + data_test['q0']*data_test['control_cf_outcome']\n",
    "\n",
    "    # Y - mu(X,A)\n",
    "    residual = data_test[outcome] - data_test['predicted_y']\n",
    "\n",
    "    w0 = [0 if data_test.loc[i,treatment] == 1 else 1/data_test.loc[i, 'p0'] for i in range(len(data_test))]\n",
    "    w1 = [0 if data_test.loc[i,treatment] == 0 else 1/data_test.loc[i, 'p1'] for i in range(len(data_test))]\n",
    "    w0 = np.array(w0)\n",
    "    w1 = np.array(w1)\n",
    "\n",
    "    phi_0 = w0 * residual + data_test['treated_cf_outcome'] \n",
    "    phi_1 = w1 * residual + data_test['control_cf_outcome']\n",
    "\n",
    "    avg_phi = data_test['q1']*phi_1 + data_test['q0']*phi_0\n",
    "\n",
    "    diff_cf = data_test['treated_cf_outcome'] - data_test['control_cf_outcome']\n",
    "    diff_ps = data_test[treatment] - data_test['p1']\n",
    "    modi_ps = (delta*data_test['p1'] + data_test['p0'])**2\n",
    "\n",
    "    avg_diff = (delta*diff_cf*diff_ps) / modi_ps\n",
    "    influence = avg_phi + avg_diff - estimator\n",
    "    return influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a super learner for regression using the mlens library\n",
    "from math import sqrt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    " \n",
    "# create a list of base-models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(LinearRegression())\n",
    "    models.append(ElasticNet())\n",
    "    models.append(SVR(gamma='scale'))\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(KNeighborsRegressor())\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(BaggingRegressor(n_estimators=10))\n",
    "    models.append(RandomForestRegressor(n_estimators=10))\n",
    "    models.append(ExtraTreesRegressor(n_estimators=10))\n",
    "    return models\n",
    " \n",
    "# cost function for base models\n",
    "def rmse(yreal, yhat):\n",
    "    return sqrt(mean_squared_error(yreal, yhat))\n",
    " \n",
    "# create the super learner\n",
    "def get_super_learner(X):\n",
    "    ensemble = SuperLearner(scorer=rmse, folds=10, shuffle=True, sample_size=len(X))\n",
    "    # add base models\n",
    "    models = get_models()\n",
    "    ensemble.add(models)\n",
    "    # add the meta model\n",
    "    ensemble.add_meta(LinearRegression())\n",
    "    return ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data(PATH_TRAIN, 40)\n",
    "data_test  = load_data(PATH_TEST, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "num_of_delta = 10\n",
    "delta_seq = np.linspace(0.5, 5, num_of_delta)\n",
    "\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 1)\n",
    "\n",
    "influence_sample = []\n",
    "for train_index, test_index in tqdm(kf.split(data_train)):\n",
    "    \n",
    "    df_train = data_train.iloc[train_index]\n",
    "    df_test = data_train.iloc[test_index]\n",
    "    \n",
    "    df_train = df_train.reset_index().drop(columns = ['index'])\n",
    "    df_test = df_test.reset_index().drop(columns = ['index'])\n",
    "\n",
    "    model_y = get_super_learner(df_train)\n",
    "    model_y.fit(df_train[features].values, df_train[outcome].values)\n",
    "    \n",
    "    ## Fit treatment\n",
    "    model_t = LogisticRegression()\n",
    "    model_t.fit(df_train[cov], df_train[treatment])\n",
    "    \n",
    "    influence_delta = []\n",
    "    \n",
    "    for sample_delta in tqdm(delta_seq):\n",
    "        influence = cal_influence_function_model(sample_delta, df_train, df_test, model_y, model_t, cov, treatment, outcome)\n",
    "        influence_delta.append(np.mean(influence))\n",
    "        \n",
    "    influence_sample.append(np.mean(influence_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effect = data_train['mu1'] - data_train['mu0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = np.mean(true_effect, axis=0), sem(true_effect, axis=0)\n",
    "print('True effect: {:.3f}+-{:.3f}'.format(means, stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = np.mean(influence_sample, axis=0), sem(influence_sample, axis=0)\n",
    "print('True effect: {:.3f}+-{:.3f}'.format(means, stds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_env] *",
   "language": "python",
   "name": "conda-env-.conda-phd_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "309.167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
